[
  {
    "objectID": "intro.html#guidelines-on-the-sharing-and-use-of-data-in-obis",
    "href": "intro.html#guidelines-on-the-sharing-and-use-of-data-in-obis",
    "title": "1  Introduction",
    "section": "1.1 Guidelines on the sharing and use of data in OBIS",
    "text": "1.1 Guidelines on the sharing and use of data in OBIS\nIt is important that our data providers as well as all the data users are aware and agree on the OBIS guidelines on the sharing and use of data in OBIS, which was adoped at the 4th OBIS Steering Group."
  },
  {
    "objectID": "intro.html#acknowledgements",
    "href": "intro.html#acknowledgements",
    "title": "1  Introduction",
    "section": "1.2 Acknowledgements",
    "text": "1.2 Acknowledgements\nThis manual received contributions from: Leen Vandepitte, Mary Kennedy, Philip Goldstein, Pieter Provoost, Samuel Bosch, Ward Appeltans, Abby Benson, Yi-Ming Gan, Carolina Peralta Brichtova, Saara Suominen, Serita van der Wal, and Elizabeth Lawrence."
  },
  {
    "objectID": "intro.html#data-policy",
    "href": "intro.html#data-policy",
    "title": "1  Introduction",
    "section": "1.3 Data Policy",
    "text": "1.3 Data Policy\n\n1.3.1 Guidelines on the sharing and use of data in OBIS\nAdopted at SG-OBIS-IV (Feb 2015) and IODE-XXIII (March 2015).\nThe OBIS data policy is based on the principles of timely, free and unrestricted access to biodiversity data for the benefit of science and society, as defined in the:\n\nIOC data exchange policy\nIOC guidelines on transfer of marine technology\nIODE objectives\nOBIS vision and mission\n\nUnless data are collected through activities funded by IOC/IODE, neither UNESCO, IOC, IODE, the OBIS Secretariat, nor its employees or contractors, own the data in OBIS and they take no responsibility for the quality of data or products based on OBIS, or the use or misuse that people may make of them nor can it control or limit the use of any data or products accessible through its website, other than through the use of a published Data Sharing and Use Terms and Conditions.\n\n1.3.1.1 Data sharing agreement\nThe data providers retain all rights and responsibilities associated with the data they make available to OBIS via the OBIS nodes. The OBIS nodes warrant that they have made the necessary agreements with the original data providers that it can make the data available to OBIS data under the Creative Commons licenses.\nThe data providers are responsible for the completeness of the data and metadata profiles. When data is made available to OBIS, OBIS is granted permission to:\n\nDistribute the data via its data and information portal\nBuild an integrated database, use the data for data quality control purposes, complement the data with other data such as climate variables and build value-added information products and services for science and decision-making\nServe the data to other similar open-access networks such as GBIF in compliance with the terms and conditions for use set by the data providers.\n\nIn pursuance of copyright compliance, OBIS endeavours to secure permission from rights holders to ingest their datasets. In the event that the inclusion of a dataset in OBIS is challenged on the basis of copyright infringement, OBIS will follow a take-down policy until there is resolution.\n\n\n1.3.1.2 Data use agreement\nThe data in OBIS are freely available to everyone, following the principles of equitable access and benefit sharing and supporting capacity development and participation of all IOC Member States in global programmes. However, data users are expected to give attribution to the data providers (see Citations) and the use of data from OBIS should happen in the light of fair use, i.e.:\n\nRecognize that the OBIS portal holds the master copy of the integrated database and hence users should refrain from online redistribution of the OBIS database. Because the OBIS database is updated regularly (every so months) with new datasets and revisions of existing datasets, copies of the OBIS database will become out of date quickly. If you wish to build access web services on top of OBIS, please contact the OBIS secretariat.\nRespect the data providers, and provide helpful feedback on data quality.\nIn the case you are a custodian of biogeographic data yourself you should take action to also publish these data through OBIS.\nConsider sponsoring or partnering with OBIS and its OBIS nodes in grant proposal writing. Creating a global database like OBIS cannot happen without the, often voluntary, contribution of many scientists and data managers all over the world. Several activities, such as the coordination, data aggregation, quality control, database and website maintenance require resources including manpower at national and international level. A list of sponsors can be found here\n\n\n\n1.3.1.3 Disclaimer\nAppropriate caution is necessary in the interpretation of results derived from OBIS. Users must recognize that the analysis and interpretation of data require background knowledge and expertise about marine biodiversity (including ecosystems and taxonomy). Users should be aware of possible errors, including in the use of species names, geo-referencing, data handling, and mapping. They should crosscheck their results for possible errors, and qualify their interpretation of any results accordingly.\nUnless data are collected through activities funded by IOC/IODE, neither UNESCO, IOC, IODE, the OBIS Secretariat, nor its employees or contractors, own the data in OBIS and they take no responsibility for the quality of data or products based on OBIS, or the use or misuse."
  },
  {
    "objectID": "intro.html#getting-help-in-obis",
    "href": "intro.html#getting-help-in-obis",
    "title": "1  Introduction",
    "section": "1.4 Getting Help in OBIS",
    "text": "1.4 Getting Help in OBIS\nIf you require additional assistance with OBIS we recommend you first get in touch with the most relevant OBIS node. We also have a support channel on Slack where you can communicate with the OBIS community for help. Please feel comfortable posting to this channel before reaching out to the OBIS Secretariat (helpdesk@obis.org). The OBIS community is quite active on Slack and GithHub (see below) so you are more likely to receive a quick answer to your question by posting in either place, as the Secretariat receives many requests.\nYou can submit issues and questions on relevant Github repositories:\n\nOBIS Manual\nOBIS issues GitHub repo\nOBIS quality control issues\nAll other OBIS repositories\n\nWe strongly recommend creating a GitHub account to engage with the OBIS community, document issues, ask questions, find datasets that need endorsing, etc. GitHub gives threads a more permanent home and allows for open communication and transparency. If you are unfamiliar with GitHub, the Carpentries have these training resources which you can reference."
  },
  {
    "objectID": "contribute.html#why-publish-data-to-obis",
    "href": "contribute.html#why-publish-data-to-obis",
    "title": "2  What can you contribute and how?",
    "section": "2.1 Why publish data to OBIS",
    "text": "2.1 Why publish data to OBIS\nIt is important to publish and ensure your dataset follows a universal standard for several reasons. The FAIR guiding principles for scientific data management and stewardship provide a good framework to understand the reasoning behind publishing data. FAIR stands for Findable, Accessible, Interoperable, and Reusable. Let’s understand each aspect within the FAIR framework and how it is linked to publishing data in OBIS.\n\nF - Findable\n\nEven if you publish your dataset on its own, publishing your data with OBIS will make your data more Findable (and Accessible) to a wider audience you might not have otherwise reached. By publishing your dataset to OBIS you are adding to a global database where your data can be found and analyzed alongside thousands of other datasets. For example, a dataset on marine invasive species in Venezuela was published July 20, 2022 and as of October 5, 2022 records of this dataset were included in 1,873 data download requests. This can save you time rather than handling individual data requests.\n\nA - Accessible\n\nSimilar to being Findable, OBIS makes your datasets more Accessible. Each dataset is given an identifier when you upload it on an IPT. Thus when users obtain data from OBIS, the original dataset can easily be identified and accessed. Data from OBIS is accessible in numerous ways, giving data users multiple avenues to potentially access your data.\n\nI - Interoperable\n\nUsing a standardized data format with controlled vocabularies will ensure your data are more Interoperable - more easily interpreted and processed by computers and humans alike. Increasingly, scientists use computer programs to conduct e-Science and collect data with algorithms. Formatting your data for OBIS will ensure it can be read and accessed by such programs as well as understood by users.\n\nR - Reusable\n\nPublishing your data allows it to be Reused according to your chosen data usage license. Very likely you expended resources to collect your data and it would be a waste of those resources to leave your unique data unpublished and inaccessible for current and future generations. Likewise, it is better to preserve any data processing done to ensure your dataset is reproducible and/or verifiable. Finally, data in OBIS is often used in several assessment processes and used as information to support policy makers around the globe making informed decisions.\nThere are many other benefits of publishing in OBIS, even if you haven’t published any work on it yet. This includes:\n\nYour dataset can be associated with a DOI, allowing for your dataset to be more easily cited. By ensuring your dataset citation is complete you will ensure you are being cited properly.\nPublishing your dataset with OBIS makes it easier to set it up as a Data paper, which generates value for you and other researchers.\nThere are social benefits to data publishing as your work becomes integrated into a wider dataset. It gives both you and your data more visibility. This can lead to more opportunities for collaboration and further career development as a researcher or professional.\nYour data can be incorporated into larger analyses to better understand global ocean biodiversity, helping to shape regional and international policies."
  },
  {
    "objectID": "contribute.html#how-to-handle-sensitive-data",
    "href": "contribute.html#how-to-handle-sensitive-data",
    "title": "2  What can you contribute and how?",
    "section": "2.2 How to handle sensitive data",
    "text": "2.2 How to handle sensitive data\nWe recognize that sometimes your dataset may contain sensitive information (e.g., location data on endangered or poached species), or perhaps your organization does not want certain details publicly accessible. Types of sensitive data include:\n\nLocation data on endangered or protected species\nInformation regarding a commonly poached species\nSpecies or locations that have an economic impact (positive or negative)\n\nTo accommodate sensitivity but still be able to contribute to OBIS, we suggest:\n\nGeneralizing location information by: Obtaining regional coordinates using MarineRegions, Getty Thesaurus of Geographic Names, or Google Maps\nUsing the OBIS Map tool to generate a polygon area with a Well-Known Text (WKT) representation of the geometry to paste into the footprintWKT field.\nDelay timing of publication (e.g., to accommodate mobile species)\nSubmit your dataset, but mark it as private in the IPT so it is not published right away (i.e., until you set it as public). Alternatively, you can set a password on your dataset in order to share with specific individuals. Note that setting passwords will require some coordination with the IPT manager. By submitting your data to an IPT but not immediately publishing it, you can ensure that the dataset will be in a place to be incorporated at a later date when it is ready to be made public. This not only saves time and helps retain details while relatively fresh in your mind, but also ensures the dataset is still ready to be mobilized in case jobs are changed at a later date.\n\nGBIF has created the following Best Practices for Generalizing Sensitive data which can provide you with additional guidance. Chapman AD (2020) Current Best Practices for Generalizing Sensitive Species Occurrence Data. Copenhagen: GBIF Secretariat. https://doi.org/10.15468/doc-5jp4-5g10."
  },
  {
    "objectID": "contribute.html#obis-data-life-cycle",
    "href": "contribute.html#obis-data-life-cycle",
    "title": "2  What can you contribute and how?",
    "section": "2.3 OBIS Data Life Cycle",
    "text": "2.3 OBIS Data Life Cycle\n\n\n\n\nThe basic data life cycle for contributions to OBIS can be broken down into six step-by-step phases:\n\nData structure\nData formatting\nQuality control\nPublishing\nData access (downloading)\nData visualization\n\nEach of these phases are outlined in this manual and are composed of a number of steps which are covered in the relevant sections.\nAfter you have decided on your data structure and have moved to the Data Formatting stage, you must first match the taxa in your dataset to a registered list. In formatting your dataset you will ensure the required OBIS terms and identifiers are mapped correctly to your data fields and records.\nDepending on your data structure, you will then format data into a DwC-A format with the appropriate Core table (Event or Occurrence) with any applicable extension tables. Any biotic or abiotic measurements will be moved into the extendedMeasurementOrFact table. Before proceeding to the publishing stage, there are a number of quality control steps to complete.\nOnce your data has been published, you and others can access datasets through various avenues and it becomes part of OBIS’ global database!\nThis may seem like a daunting process at first glance, but this manual will walk you through each step, and the OBIS community is full of helpful resources. Throughout the manual you will find tutorials and tools to guide you from start to finish through the OBIS data life cycle.\n\n\n2.3.0.1 Who is responsible for each phase?\nPhases 1 through 3 are the responsibilities of the data provider, while Phases 3 and 4 are shared between the data provider and the node manager. Data users are involved in Phases 5 and 6.\nThe OBIS Secretariat is responsible for data processing and harvesting published resources."
  },
  {
    "objectID": "contribute.html#biodiversity-data-standards",
    "href": "contribute.html#biodiversity-data-standards",
    "title": "2  What can you contribute and how?",
    "section": "2.4 Biodiversity data standards",
    "text": "2.4 Biodiversity data standards\nFrom the very beginning, OBIS has championed the use of international standards for biogeographic data. Without agreement on the application of standards and protocols, OBIS would not have been able to build a large central database. OBIS uses the following standards:\n\nDarwin Core\nEcological Metadata Language\nDarwin Core Archive and dataset structure\n\nThe following pages of this manual review each of these in turn. We show you how to apply these standards to format your data in the Data Formatting section.\nWe also provide some dataset examples for your reference.\n\n2.4.1 Darwin Core\nContents\n\nIntroduction to Darwin Core\nDarwin Core terms\n\nDarwin Core guidelines\n\nTaxonomy and identification\nOccurrence\n\nRecord level terms\n\nLocation\n\nEvent\nTime\n\nSampling\n\n\n\n2.4.1.1 Introduction to Darwin Core\nDarwin Core is a body of standards (i.e., identifiers, labels, definitions) that facilitate sharing biodiversity informatics. It provides stable terms and vocabularies related to biological objects/data and their collection. Darwin Core is maintained by TDWG (Biodiversity Information Standards, formerly The International Working Group on Taxonomic Databases). Stable terms and vocabularies are important for ensuring the datasets in OBIS have consistently interpretable fields. By following Darwin Core standards, both data providers and users can be certain of the definition and quality of data.\n\n2.4.1.1.1 History of Darwin Core and OBIS\nThe old OBIS schema was an OBIS extension to Darwin Core 1.2., which was based on Simple Darwin Core, a subset of Darwin Core which does not allow any structure beyond rows and columns. This old schema added some terms which were important for OBIS, but were not supported by Darwin Core at the time (e.g., start and end date and start and end latitude and longitude, depth range, lifestage, and terms for abundance, biomass and sample size).\nIn 2009, the Executive Committee of TDWG announced their ratification of an updated version of Darwin Core as a TDWG Standard. Ratified Darwin Core unifies specializations and innovations emerging from diverse communities, and provides guidelines for ongoing enhancement. The Darwin Core Quick Reference Guide links to TDWG’s term definitions and related practices for Ratified Darwin Core. We will discuss the relevance of terms in this guide further below.\nIn December 2013, the 3rd session of the IODE Steering Group for OBIS agreed to transition OBIS globally to the TDWG-Ratified version of Darwin Core, and the mapping of the (old) OBIS specific terms to Darwin Core can be found here.\n\n\n\n\n2.4.1.2 Darwin Core (DwC) terms\nDwC terms correspond to the column names of your dataset and can be grouped according to class type for convenience, e.g., Taxa, Occurrence, Record, Location, etc. It is important to use DwC field names because only columns using Darwin Core terms as headers will be recognized.\nA list of all possible Darwin Core terms can be found on TDWG. However, OBIS does not parse all terms (note this doesn’t mean you cannot include them, they just will not be parsed when you publish to OBIS). Below is an overview of the most relevant Darwin Core terms to consider when contributing to OBIS, with guidelines regarding their use. We have also compiled a convenient checklist of OBIS-accepted terms, their DwC class type, and which OBIS file (Event Core, Occurrence, eMoF, etc.) it is likely to be found in.\nNote that OBIS currently has seven required and one strongly recommended DwC term: occurrenceID, eventDate, decimalLongitude, decimalLatitude, scientificName, occurrenceStatus, basisOfRecord, scientificNameID (strongly recommended).\nThe following DwC terms are related to the Class Taxon:\n\nscientificName\nscientificNameID\nscientificNameAuthorship\nkingdom\ntaxonRank\ntaxonRemarks\n\nThe following DwC terms are related to the Class Identification:\n\nidentifiedBy\ndateIdentified\nidentificationReferences\nidentificationRemarks\nidentificationQualifier\ntypeStatus\n\nThe following DwC terms are related to the Class Occurrence:\n\noccurrenceID\noccurrenceStatus\nrecordedBy\nindividualCount (OBIS recommends to add measurements to eMoF)\norganismQuantity (OBIS recommends to add measurements to eMoF)\norganismQuantityType (OBIS recommends to add measurements to eMoF)\nsex (OBIS recommends to add measurements to eMoF)\nlifeStage (OBIS recommends to add measurements to eMoF)\nbehavior\nassociatedTaxa\noccurrenceRemarks\nassociatedMedia\nassociatedReferences\nassociatedSequences\ncatalogNumber\npreparations\n\nThe following DwC terms are related to the Class Record level:\n\nbasisOfRecord\ninstitutionCode\ncollectionCode\ncollectionID\nbibliographicCitation\nmodified\ndataGeneralizations\n\nThe following DwC terms are related to the Class Location:\n\ndecimalLatitude\ndecimalLongitude\ncoordinateUncertaintyInMeters\ngeodeticDatum\nfootprintWKT\nminimumDepthInMeters\nmaximumDepthInMeters\nminimumDistanceAboveSurfaceInMeters\nmaximumDistanceAboveSurfaceInMeters\nlocality\nwaterBody\nislandGroup\nisland\ncountry\nlocationAccordingTo\nlocationRemarks\nlocationID\n\nThe following DwC terms are related to the Class Event:\n\nparentEventID\neventID\neventDate\ntype\nhabitat\nsamplingProtocol (OBIS recommends to add sampling facts to eMoF)\nsampleSizeValue (OBIS recommends to add sampling facts to eMoF)\nSampleSizeUnit (OBIS recommends to add sampling facts to eMoF)\nsamplingEffort (OBIS recommends to add sampling facts to eMoF)\n\nThe following DwC terms are related to the Class MaterialSample:\n\nmaterialSampleID\n\n\n\n2.4.1.3 Darwin Core guidelines\n\n2.4.1.3.1 Taxonomy and identification\nscientificName (required term) should always contain the originally recorded scientific name, even if the name is currently a synonym. This is necessary to be able to track back records to the original dataset. The name should be at the lowest possible taxonomic rank, preferably at species level or lower, but higher ranks, such as genus, family, order, class etc. are also acceptable. We recommend to not include authorship in scientificName, and only use scientificNameAuthorship for that purpose. The scientificName term should only contain the name and not identification qualifications (such as ?, confer or affinity), which should instead be supplied in the IdentificationQualifier term, see examples below. taxonRemarks can capture comments or notes about the taxon or name.\nA WoRMS LSID should be added in scientificNameID (strongly recommended term), OBIS will use this identifier to pull the taxonomic information from the World Register of Marine Species (WoRMS) into OBIS and attach it to your dataset. This information includes:\n\nTaxonomic classification (kingdom through species)\nThe accepted name in case of invalid names or synonyms\nAphiaID\nIUCN red list category\n\nLSIDs are persistent, location-independent, resource identifiers for uniquely naming biologically significant resources. More information on LSIDs can be found at www.lsid.info. For example, the WoRMS LSID for Solea solea is: urn:lsid:marinespecies.org:taxname:127160, and can be found at the bottom of each WoRMS taxon page, e.g. Solea solea.\nkingdom and taxonRank can help us in identifying the provided scientificName in case the name is not available in WoRMS. kingdom in particular can help us find alternative genus-species combinations and avoids linking the name to homonyms. Please contact the WoRMS data management team (info@marinespecies.org) in case the scientificName is missing in WoRMS. kingdom and taxonRank are not necessary when a correct scientificNameID is provided.\nOBIS recommends providing information about how an identification was made, for example by which ID key, species guide or expert; and by which method (e.g morphology vs. genomics), etc. The person’s name who made the taxonomic identification can go in identifiedBy and when in dateIdentified. Use the ISO 8601:2004(E) standard for date and time, for instructions see Time. A list of references, such as field guides used for the identification can be listed in identificationReferences. Any other information, such as identification methods, can be added to identificationRemarks.\nExamples:\n\n\n\n\n\n\n\n\n\n\n\n\nscientificNameID\nscientificName\nkingdom\nphylum\nclass\n\n\n\n\nurn:lsid:marinespecies.org:taxname:142004\nYoldiella nana\nAnimalia\nMollusca\nBivalvia\n\n\nurn:lsid:marinespecies.org:taxname:140584\nEnnucula tenuis\nAnimalia\nMollusca\nBivalvia\n\n\nurn:lsid:marinespecies.org:taxname:131573\nTerebellides stroemii\nAnimalia\nAnnelida\nPolychaeta\n\n\n\n\n\n\nData from Benthic fauna around Franz Josef Land.\n\n\norder\nfamily\ngenus\nspecificEpithet\nscientificNameAuthorship\n\n\n\n\nNuculanoida\nYoldiidae\nYoldiella\nnana\n(Sars M., 1865)\n\n\nNuculoida\nNuculidae\nEnnucula\ntenuis\n(Montagu, 1808)\n\n\nTerebellida\nTrichobranchidae\nTerebellides\nstroemii\nSars, 1835\n\n\n\n\nIf the record represents a nomenclatural type specimen, the term typeStatus can be used, e.g. for holotype, syntype, etc.\nIn case of low confidence identifications, and the scientific name contains qualifiers such as cf., ? or aff., then this name should go in identificationQualifier, and scientificName should contain the name of the lowest possible taxon rank that refers to the most accurate identification. E.g. if the specimen was accurately identified down to genus level, but not species level, then the scientificName should contain the name of the genus, the scientificNameID should contain the LSID the genus and the identificationQualifier should contain the low confidence species name combined with ? or other qualifiers. The table below shows a few examples:\nThe use and definitions for additional ON signs (identificationQualifier) can be found in Open Nomenclature in the biodiversity era, which provides examples for using the main Open Nomenclature qualifiers associated with physical specimens. The publication Recommendations for the Standardisation of Open Taxonomic Nomenclature for Image-Based Identiﬁcations provides examples and definitions for identificationQualifiers for non-physical specimens (image-based).\nExamples:\n\n\n\n\n\n\n\n\n\n\n\n\n\nscientificName\nscientificNameAuthorship\nscientificNameID\ntaxonRank\nidentificationQualifier\ntaxonConceptID\n\n\n\n\nPelagia\nPéron & Lesueur, 1810\nurn:lsid:marinespecies.org:taxname:135262\ngenus\ngen. nov.\nPelagia gen. nov.\n\n\nPelagia benovici\nPiraino, Aglieri, Scorrano & Boero, 2014\nurn:lsid:marinespecies.org:taxname:851656\nspecies\nsp. nov\nPelagia benovici sp. nov\n\n\nGadus\nLinnaeus, 1758\nurn:lsid:marinespecies.org:taxname:125732\ngenus\ncf. morhua\nGadus cf. morhua\n\n\nPolycera\nCuvier, 1816\nurn:lsid:marinespecies.org:taxname:138369\ngenus\ncf. hedgpethi\nPolycera cf. hedgpethi\n\n\nTubifex\nLamarck, 1816\nurn:lsid:marinespecies.org:taxname:137392\ngenus\n?\nTubifex tubifex(Müller, 1774)?\n\n\nTubifex\nLamarck, 1816\nurn:lsid:marinespecies.org:taxname:137392\ngenus\nsp. inc.\nTubifex tubifex(Müller, 1774)sp. inc.\n\n\nBrisinga\nAsbjørnsen, 1856\nurn:lsid:marinespecies.org:taxname:123210\ngenus\ngen. inc.\nBrisinga gen. inc.\n\n\nUroptychus compressus\nBaba & Wicksten, 2019\nurn:lsid:marinespecies.org:taxname:1332465\ngenus\nsp. inc.\nUroptychus compressus sp. inc.\n\n\nEurythenes\nS. I. Smith in Scudder, 1882\nurn:lsid:marinespecies.org:taxname:101607\ngenus\nsp. DISCOLL.PAP.JC165.674\nEurythenes sp.DISCOLL.PAP.JC165.674\n\n\nParoriza\nHérouard, 1902\nurn:lsid:marinespecies.org:taxname:123467\ngenus\nsp.[unique123]aff.pallens\nParoriza sp.[unique123]aff. pallens\n\n\nAristeidae\nWood-Mason in Wood-Mason & Alcock, 1891\nurn:lsid:marinespecies.org:taxname:106725\nfamily\nstet.\nAristeidae stet.\n\n\nNematocarcinus\nMilne-Edwards, 1881\nurn:lsid:marinespecies.org:taxname:107015\ngenus\nsp.indet.\nNematocarcinus sp.indet.\n\n\nBrisinga\nAsbjørnsen, 1856\nurn:lsid:marinespecies.org:taxname:123210\ngenus\ngen.inc.\nBrisinga gen.inc.\n\n\nBrisinga costata\nVerrill, 1884\nurn:lsid:marinespecies.org:taxname:17825\nspecies\nsp.inc.\nBrisinga costata sp.inc.\n\n\n\n\n\n\n2.4.1.3.2 Occurrence\noccurrenceID (required term) is an identifier for the occurrence record and should be persistent and globally unique. If the dataset does not yet contain (globally unique) occurrenceIDs, then they should be created. Guideline for ID creation can be found here\noccurrenceStatus (required term) is a statement about the presence or absence of a taxon at a location. It is an important term, because it allows us to distinguish between presence and absence records. It is a required term and should be filled in with either present or absent.\nA few terms related to quantity: organismQuantity and organismQuantityType, have been added to the TDWG ratified Darwin Core. This is a lot more versatile than the older individualCount field. However, OBIS recommends to use the Extended MeasurementorFact extension for quantitative measurements because of the standardization of terms and the fact that you can link these measurements to sampling events and factual sampling information.\nPlease take note that OBIS recommends all quantitative measurements and sampling facts to be placed in the ExtendedMeasurementOrFact extension and not in the Darwin Core files.\nIn the case specimens were collected and stored (e.g. museum collections), the catalogNumber and preparations terms can be used to provide the identifier for the record in the collection and to document the preparation and preservation methods. The term typeStatus see above (under identification) can be used in this context too.\nBoth associatedMedia, associatedReferences and associatedSequences are global unique identifiers or URIs pointing to respectively associated media (e.g. online image or video), associated literature (e.g. DOIs) or genetic sequence information (e.g. GenBANK ID).\nassociatedTaxa include a list (concatenated and separated) of identifiers or names of taxa and their associations with the Occurrence, e.g. the species occurrence was associated to the presence of kelp such as Laminaria digitata.\nThe recommended vocabulary for sex see BODC vocab : S10, for lifeStage see BODC vocab: S11, behavior (no vocab available), and occurrenceRemarks can hold any comments or notes about the Occurrence.\nrecordedBy can hold a list (concatenated and separated) of names of people, groups, or organizations responsible for recording the original Occurrence. The primary collector or observer, especially one who applies a personal identifier (recordNumber), should be listed first.\nExample:\n\n\nData from A summary of benthic studies in the sluice dock of Ostend during 1976-1981.\n\n\ncollectionCode\noccurrenceID\ncatalogNumber\noccurrenceStatus\n\n\n\n\nSluiceDock_benthic_1976/1981\nSluiceDock_benthic_1976_1\nSluiceDock_benthic_1976_1\npresent\n\n\nSluiceDock_benthic_1976/1981\nSluiceDock_benthic_1976_2\nSluiceDock_benthic_1976_2\npresent\n\n\nSluiceDock_benthic_1976/1981\nSluiceDock_benthic_1979-07/1980-06_1\nSluiceDock_benthic_1979-07/1980-06_1\npresent\n\n\n\n\n\n\n2.4.1.3.3 Record level terms\nbasisOfRecord (required term) specifies the nature of the record, i.e. whether the occurrence record is based on a stored specimen or an observation. In case the specimen is collected and stored in a collection (e.g. at a museum, university, research institute), the options are:\n\nPreservedSpecimen e.g. preserved in ethanol, tissue etc.\nFossilSpecimen a fossil, which allows OBIS to make the distinction between the date of collection and the time period the specimen was assumed alive\nLivingSpecimen an intentionally kept/cultivated living specimen e.g. in an aquarium or culture collection.\n\nIn case no specimen is deposited, the basis of record is either HumanObservation (e.g bird sighting, benthic sample but specimens were discarded after counting), or MachineObservation (e.g. for occurrences based on automated sensors such as image recognition, etc). For records pertaining to genetic samples, basisOfRecord can be MaterialSample (e.g. in the DNA-derived data extension).\nWhen the basisOfRecord is either a preservedSpecimen, LivingSpecimen or FossilSpecimen please also add the institutionCode, collectionCode and catalogNumber, which will enable people to visit the collection and re-examine the material. Sometimes, for example in case of living specimens, a dataset can contain records pointing to the origin, the in-situ sampling position as well as a record referring to the ex-situ collection. In this case please add the event type information in eventRemarks (see OBIS manual: event).\ninstitutionCode identifies the custodian institute (often by acronym), collectionCode identifies the collection or dataset within that institute. Collections cannot belong to multiple institutes, so all records within a collection should have the same institutionCode. The collectionID is an identifier for the record within the dataset or collection.\nbibliographicCitation allows for providing different citations on record level, while a single citation for the entire dataset can and should be provided in the metadata (see EML). The citation at record level can have the format of a chapter in a book, where the book is the dataset citation. The record citation will have preference over the dataset citation. We do not, however, recommend to create different citations for every record, as this will explode the number of citations and will hamper the re-use of data.\nmodified is the most recent date-time on which the resource was changed. It is required to use the ISO 8601:2004(E) standard, for instructions see Time.\ndataGeneralizations refers to actions taken to make the shared data less specific or complete than in its original form. Suggests that alternative data of higher quality may be available on request. This can be the case for occurrences of vulnerable or endangered species and there positions are converted to the center of grid cells.\n\n\n\n2.4.1.3.4 Location\ndecimalLatitude and decimalLongitude (required terms) are the geographic latitude and longitude (in decimal degrees), using the spatial reference system given in geodeticDatum of the geographic center of a Location. The number of decimals should be appropriate for the level of uncertainty in coordinateUncertaintyInMeters (at least within an order of magnitude). coordinateUncertaintyInMeters is the radius of the smallest circle around the given position containing the whole location. Regarding decimalLatitude, positive values are north of the Equator, negative values are south of it. All values lie between -90 and 90, inclusive. Regarding decimalLongitude, positive values are east of the Greenwich Meridian, negative values are west of it. All values lie between -180 and 180, inclusive.\nIn OBIS, the spatial reference system to be documented in geodeticDatum is EPSG:4326. Coordinates in degrees/minutes/seconds can be converted to decimal degrees using our coordinates tool. We also provide a tool to check coordinates or to determine coordinates for a location (point, transect or polygon) on a map. This tool also allows geocoding location names using marineregions.org.\nThe name of the place or location can be provided in locality, and if possible linked by a locationID using a persistent ID from a gazetter, such as the MRGID from MarineRegions. If the species occurrence only contains the name of the locality, but not the exact coordinates, we recommend using a geocoding service to obtain the coordinates. Marine Regions has a search interface for geographic names, and provides coordinates and often precision in meters, which can go into coordinateUncertaintyInMeters. Another option is to use the Getty Thesaurus of Geographic Names or Google Maps: after looking up a location, the decimal coordinates can be found in the page URL. Additional information about the locality can also be stored in DwC terms such as waterBody, islandGroup, island and country. locationAccordingTo should provide the name of the gazetteer that is used to obtain the coordinates for the locality.\nlocationID is an identifier for the set of location information (e.g. station ID, or MRGID from marineregions), for example the Balearic Plain has MRGID: http://marineregions.org/mrgid/3956.\nA Well-Known Text (WKT) representation of the shape of the location can be provided in footprintWKT. This is particularly useful for tracks, transects, tows, trawls, habitat extent or when an exact location is not known. WKT strings can be created using our WKT tool. This tool also calculates a midpoint and a radius, which can then be added to decimalLongitude, decimalLatitude, and coordinateUncertaintyInMeters respectively. There is also an R tool to calculate the centroid and radius for WKT polygons. wktmap.com can be used to visualize and share WKT strings.\n\n\nSome examples of WKT strings:\nLINESTRING (30 10, 10 30, 40 40)\nPOLYGON ((30 10, 40 40, 20 40, 10 20, 30 10))\nMULTILINESTRING ((10 10, 20 20, 10 40),(40 40, 30 30, 40 20, 30 10))\nMULTIPOLYGON (((30 20, 45 40, 10 40, 30 20)),((15 5, 40 10, 10 20, 5 10, 15 5)))\nExample:\n\n\nData from Adriatic and Ionian Sea mega-fauna monitoring employing ferry as platform of observation along the Ancona-Igoumenitsa-Patras lane, from December 2014 to December 2018.\n\n\ndecimalLatitude\ndecimalLongitude\ngeodeticDatum\ncoordinateUncertaintyInMeters\nfootprintWKT\nfootprintSRS\n\n\n\n\n38.698\n20.95\nEPSG:4326\n75033.17\nLINESTRING (20.31 39.15, 21.58 38.24)\nEPSG:4326\n\n\n42.72\n15.228\nEPSG:4326\n154338.87\nLINESTRING (16.64 41.80, 13.82 43.64)\nEPSG:4326\n\n\n39.292\n20.364\nEPSG:4326\n162083.27\nLINESTRING (19.05 40.34, 21.68 38.25)\nEPSG:4326\n\n\n\n\nKeep in mind while filling in minimumDepthInMeters and maximumDepthInMeters that this should be the depth at which the sample was taken and not the water column depth at that location. When fillling in any depth fields (minimumDepthInMeters, maximumDepthInMeters, minimumDistanceAboveSurfaceInMeters, and maximumDistanceAboveSurfaceInMeters), you should also consider which information is needed to fully understand the data. In most cases (e.g. scenario 1 and 4 in the figure below), providing minimumDepthInMeters and maximumDepthInMeters is sufficient for observations of organisms at particular depths. However, in cases where an occurrence is above the sea surface, e.g. flying birds (scenario 2 and 5), you should populate minimumDistanceAboveSurfaceInMeters, maximumDistanceAboveSurfaceInMeters, and, where relevant, you should also include minimumElevationInMeters and maximumElevationInMeters.\nThe minimumDistanceAboveSurfaceInMeters and maximumDistanceAboveSurfaceInMeters is the distance, in meters, above or below a reference surface or reference point. The reference surface is determined by the depth or elevation. If the depth and elevation are 0, then the reference surface is the sea surface. If a depth is given, the reference surface is the location of the depth. This can be especially useful for sediment cores taken from the sea bottom (scenario 3 in figure below). If no depth is given, then the elevation is the reference surface (scenario 5).\n\nDepth scenario examples:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScenario\nminimumDepthInMeters\nmaximumDepthInMeters\nminimumDistanceAboveSurfaceInMeters\nmaximumDistanceAboveSurfaceInMeters\nminimumElevationInMeters\nmaximumElevationInMeters\n\n\n\n\n1\n40, 90\n50, 100\n-\n-\n0\n0\n\n\n2\n0\n0\n10\n15\n0\n0\n\n\n3\n100\n100\n0\n-1.5\n0\n0\n\n\n4\n20\n22\n-\n-\n0\n0\n\n\n5\n0\n0\n10\n15\n10\n10\n\n\n\n\n\n\n2.4.1.3.5 Event\neventID is an identifier for the sampling or observation event. parentEventID is an identifier for a parent event, which is composed of one or more sub-sampling (child) events (eventIDs). See identifiers for details on how these terms can be constructed.\nhabitat is a category or description of the habitat in which the Event occurred (e.g. benthos, seamount, hydrothermal vent, seagrass, rocky shore, intertidal, ship wreck etc.)\n\n\n2.4.1.3.6 Time\nThe date and time at which an occurrence was recorded goes in eventDate. This term uses the ISO 8601 standard and OBIS recommends using the extended ISO 8601 format with hyphens.\n\n\n\n\n\n\nMore specific guidelines on formatting dates and times can be found in the Common Data formatting issues page\n\n\n2.4.1.3.7 Sampling\nInformation on sampleSizeValue and sampleSizeUnit is very important when an organism quantity is specified. However, with OBIS-ENV-DATA it was felt that the extended MeasurementorFact (eMoF) extension would be better suited than the DwC Event Core to store the sampled area and/or volume because in some cases sampleSize by itself may not be detailed enough to allow interpretation of the sample. For instance, in the case of a plankton tow, the volume of water that passed through the net is relevant. In case of Niskin bottles, the volume of sieved water is more relevant than the actual volume in the bottle. In these examples, as well as generally when recording sampling effort for all protocols, eMoF enables greater flexibility to define parameters, as well as the ability to describe the entire sample and treatment protocol through multiple parameters. eMoF also allows you to standardize your terms to a controlled vocabulary.\nThe next chapter deals with the metadata (description of the dataset) in Ecological Metadata Language.\n\n\n\n\n2.4.2 Darwin Core Archive\nContents\n\nDarwin Core Archive\nOBIS holds more than just species occurrences: the ENV-DATA approach\n\nExtendedMeasurementOrFact Extension (eMoF)\neDNA & DNA derived data Extension\nA special case: habitat types\n\nRecommended reading\n\n\n2.4.2.1 Darwin Core Archive\nDarwin Core Archive (DwC-A) is the standard for packaging and publishing biodiversity data using Darwin Core terms. It is the preferred format for publishing data in OBIS and GBIF. The format is described in the Darwin Core text guide. A Darwin Core Archive contains a number of text files, including data tables formatted as CSV.\nThe conceptual data model of the Darwin Core Archive is a star schema with a single core table, for example containing occurrence records or event records, at the center of the star. Extension tables can optionally be associated with the core table. It is not possible to link extension tables to other extension tables (to form a so-called snowflake schema). There is a one-to-many relationship between the core and extension records, so each core record can have zero or more extension records linked to it, and each extension record must be linked to exactly one core record. Definitions for the core and extension tables can be found here.\nBesides data tables, a Darwin Core Archive also contains two XML files: one file which describes the archive and data file structure (meta.xml), and one file which contains the dataset’s metadata (eml.xml).\n\n\nFigure: structure of a Darwin Core Archive.\n\n\n\n2.4.2.2 OBIS holds more than just species occurrences: the ENV-DATA approach\nData collected as part of marine biological research often include measurements of habitat features (such as physical and chemical parameters of the environment), biotic and biometric measurements (such as body size, abundance, biomass), as wel as details regarding the nature of the sampling or observation methods, equipment, and sampling effort.\nIn the past, OBIS relied solely on the Occurrence Core, and additional measurements were added in a structured format (e.g. JSON) in the Darwin Core term dynamicProperties inside the occurrence records. This approach had significant downsides: the format is difficult to construct and deconstruct, there is no standardization of terms, and attributes which are shared by multiple records (think sampling methodology) have to be repeated many times. The formatting problem can be addressed by moving measurements to a MeasurementOrFacts extension table, but that doesn’t solve the redundancy and standardization problems.\nWith the release and adoption of a new core type Event Core it became possible to associate measurements with nested events (such as cruises, stations, and samples), but the restrictive star schema of Darwin Core archive prohibited associating measurements with the event records in the Event core as well as with the occurrence records in the Occurrence extension. For this reason an extended version of the existing MeasurementOrFact extension was created.\n\n2.4.2.2.1 ExtendedMeasurementOrFact Extension (eMoF)\nAs part of the IODE pilot project Expanding OBIS with environmental data OBIS-ENV-DATA, OBIS introduced a custom ExtendedMeasurementOrFact or eMoF extension, which extends the existing MeasurementOrFact extension with 4 new terms:\n\noccurrenceID\nmeasurementTypeID\nmeasurementValueID\nmeasurementUnitID\n\nThe occurrenceID term is used to circumvent the limitations of the star schema, and link measurement records in the ExtendedMeasurementOrFact extension to occurrence records in the Occurrence extension. Note that in order to comply with the Darwin Core Archive standard, these records still need to link to an event record in the Event core table as well. Thanks to this term we can now store a variety of measurements and facts linked to either events or occurrences:\n\norganism quantifications (e.g. counts, abundance, biomass, % live cover, etc.)\nspecies biometrics (e.g. body length, weight, etc.)\nfacts documenting a specimen (e.g. living/dead, behaviour, invasiveness, etc.)\nabiotic measurements (e.g. temperature, salinity, oxygen, sediment grain size, habitat features)\nfacts documenting the sampling activity (e.g. sampling device, sampled area, sampled volume, sieve mesh size).\n\n\n\nFigure: Overview of an OBIS-ENV-DATA format. Sampling parameters, abiotic measurements, and occurrences are linked to events using the eventID (full lines). Biotic measurements are linked to occurrences using the new occurrenceID field of the ExtendedMeasurementOrFact Extension (dashed lines).\n\n\n\n2.4.2.2.2 eDNA & DNA derived data Extension\nDNA derived data are increasingly being used to document taxon occurrences. To ensure these data are useful to the broadest possible community, GBIF published a guide entitled Publishing DNA-derived data through biodiversity data platforms. This guide is supported by the DNA derived data extension for Darwin Core, which incorporates MIxS terms into the Darwin Core standard. eDNA and DNA derived data is linked to occurrence data with the use of occurrenceID and/ or eventID. Refer to the Examples: ENV-DATA and DNA derived data for use case examples of eDNA and DNA derived data.\n\n\n2.4.2.2.3 A special case: habitat types\nIncluding information on habitats (biological community, biotope, or habitat type) is possible and encouraged with the use of Event Core. However, beware the unconstrained nature of the terms measurementTypeID, measurementValueID, and measurementUnitID which can lead to inconsistently documented habitat measurements within the Darwin Core Archive standard. To ensure this data is more easily discoverable, understood or usable, refer to Examples: habitat data and/or Duncan et al. (2021) for use case examples and more details.\n\n\n2.4.2.2.4 Recommended reading\n\nDe Pooter et al. 2017. Toward a new data standard for combined marine biological and environmental datasets - expanding OBIS beyond species occurrences. Biodiversity Data Journal 5: e10989. hdl.handle.net/10.3897/BDJ.5.e10989\nDuncan et al. (2021). A standard approach to structuring classified habitat data using the Darwin Core Extended Measurement or Fact Extension. EMODnet report. (Note you must refine search to Technical Reports from 2021 to identify Duncan et al.’s report)\n\n\n\n\n\n2.4.3 Relational databases: the underlying framework of OBIS\nIf you are not familiar with relational databases, it can be difficult to understand the underlying framework OBIS relies on. This section will help you understand relational databases, how they relate to OBIS, the data you will format for OBIS, and the data you may download from OBIS.\nWhy do we use relational databases in the first place? You are probably familiar with flat databases which contain all data in one table - this is likely how your own data are formatted. Relational databases instead consist of multiple data tables that each contain related information. When all this information is presented in one table, the table becomes larger, very complicated, and the likelihood of data duplication increases. Relational databases seek to simplify complexities and reduce redundancy by allowing information to be self-contained, but linked to each other.\nYou can think of a relational database as separate Excel sheets or data tables that are related to each other. One data table could be a “core” table, whereas others are “extensions”. Sometimes the relationships between core and extension tables are hierarchical, but this is not always the case. There is, however, always a relationship linking core and extension tables.\nLet’s review core and extension tables and how we use them for OBIS.\nCore tables contain information that is applicable to all extension tables, and extension tables contain more information about the records within the Core table. Each table, whether core or extension, contains records and attributes. Each row is a record (e.g., a sampling event, a species’ occurrence), whereas each column is an attribute (e.g., a date, a measurement).\nRecords between tables are linked to each other by the use of identifiers. A description of measurements pertaining to a record in an Extension table will have the same identifier as the record it is describing in the Core table. By using identifiers to link records, we reduce data repetition, see below for examples. In the Darwin Core format that OBIS uses, the core table is either Event or Occurrence, and datasets can have one, none, or more extension tables. Further explanation of data formatting in OBIS is covered in the Data Formatting section of the OBIS manual.\nLet’s review an example to fully understand how relational databases work. We will look at a simple relational database used by a fictional country that tracks student performance in three different courses between three schools. Rather than trying to contain information about each school, course, and student performance in one place, this information is split into three separate tables. We see that the pink table gives us information about each school - its name, and the district it belongs to. Each school also has a schoolID, an identifier linking to the blue table where we can see student performance (course mean) in each course, the class size, and year. You will notice that the course mean and class size are bundled under columns called measurementType and measurementValue. These are similar to the eMoF vocabularies and are integral to reducing repeated data, especially when one dataset has reoccurring information. Finally we see that the courseID in the blue table links to the yellow one with the courseID identifier, giving us information about each course.\nA fourth table could easily be created to track total school population size through time. In contrast, if this information was only presented in the pink Schools in Country table, the school information would be duplicated as you add rows for each year. In this way, you can easily see how useful relational databases are. Of course, this is a simplified example but it demonstrates how related tables can be linked by identifiers to reduce table complexity and data replication.\nWe elaborate on how this structure is applied within OBIS here.\n\n\n\nAn example of how a relational database works. Three tables show the (1) student performance (blue table) in (2) different schools (pink table) in a fictional country, and (3) the names of the courses (yellow table). Information between each table is linked by the use of identifiers, indicated by the arrows\n\n\nNote that when OBIS harvests data, datasets are flattened - i.e., all separate data tables are combined into one. This is the kind of file you will receive when you download data from OBIS. The reason for this is that querying relational databases significantly reduces computational time, as opposed to querying a flat database. Relational databases also facilitate requests for subsets that meet particular criteria - e.g., all data from Norway for one species above a certain depth.\n\n2.4.3.1 How to avoid redundancy\nAvoiding redundancy and data duplication within your dataset is built into the OBIS data structure. Utilizing the ENV-DATA approach, which delineates relationships between the core table and extension tables, we can limit the repetition of data.\nFor example, let us consider the dates of a ship cruise where a series of bottom trawls were taken. The sampling information (e.g., date range, equipment used, etc.) for each species collected in these trawls is the same. Because of this, we know we are dealing with unique sampling events and thus we will use Event core. So, our Event core table will contain all information related to the sampling events (e.g., date, location). Then, information pertaining to each collected species (e.g., abundance, biomass, sampling methods, etc.) will be placed in an extension, the (Extended)MeasurementOrFact table. Here, each measurement for each species and sample will occur on a separate record. These records will be linked to the correct sampling event in the Event core by an identifier - the eventID. If we were to put this data in one file, the fields related to date and location (e.g., eventDate, decimalLongitude, decimalLatitude, etc.) would be repeated for each species.\nLet’s consider another example. If you took one temperature measurement from the water column where you took your sample, each species found in that sample would have the same temperature measurement. By linking such measurements to the event instead of each occurrence, we are able to reduce the amount of data being repeated.\n\n\n\nExample of how the sample data is distributed to Core and Extension tables, and how these tables are connected in OBIS\n\n\nAn advantage of structuring data this way is that if any mistakes are made, you only need to correct it once! So you can see that using relational event structures (when applicable) in combination with extension files can really simplify and reduce the number of times data are repeated.\nCaveat: However we would like to note that in some cases, data duplication may occur due to the star schema structure. For example, when publishing DNA-derived data, Occurrence core will have to be used, which necessitates the repetition of event data for each occurrence record.\n\n\n\n2.4.4 Ecological Metadata Language\nOBIS (and GBIF) uses the Ecological Metadata Language (EML) as its metadata standard, which is specifically developed for the earth, environmental and ecological sciences. It is based on prior work done by the Ecological Society of America and associated efforts. EML is implemented as XML. See more information on EML.\nOBIS uses the GBIF EML profile (version 1.1). In case data providers use ISO19115/ISO19139, there is a mapping available here.\nFor OBIS, the following 4 terms are the bare minimum required: Title, Citation, Contact and Abstract. Below is an overview of all the EML terms used to describe datasets:\n\ntitle [xml:lang=\"...\"]: A good descriptive title is indispensable and can provide the user with valuable information, making the discovery of data easier. Multiple titles may be provided, particularly when trying to express the title in more than one language (use the “xml:lang” attribute to indicate the language if not English/en).\ncreator ; metadataProvider ; associatedParty ; contact : These are the people and organizations responsible for the dataset resource, either as the creator, the metadata provider, contact person or any other association. The following details can be provided:\n\nindividualName\n\ngivenName\nsurName\n\norganizationName: Name of the institution.\npositionName: to be used as alternative to persons names (leave individualName blank and use positionName instead e.g. data manager).\naddress\n\ndeliveryPoint\ncity\nadministrativeArea\npostalCode\ncountry\n\nphone\n\nelectronicMailAddress\nonlineUrl : personal website\nrole: used with associatedParty to indicate the role of the associated person or organization.\nuserID: e.g. ORCID.\n\ndirectory\n\n\npubDate: The date that the resource was published. Use ISO 8601.\nlanguage: The language in which the resource (not the metadata document) is written. Use ISO language code.\nabstract : Brief description of the data resource.\n\npara\n\nkeywordSet\n\nkeyword : Note only one keyword per keyword field is allowed.\nkeywordThesaurus : e.g. ASFA\n\nadditionalInfo : OBIS checks this EML field for harvesting. It should contain marine, harvested by iOBIS.\n\npara\n\ncoverage\n\ngeographicCoverage\n\ngeographicDescription: a short text description of the area. E.g. the river mounth of the Scheldt Estuary.\nboundingCoordinates\n\nwestBoundingCoordinate\neastBoundingCoordinate\nnorthBoundingCoordinate\nsouthBoundingCoordinate\n\n\ntemporalCoverage : Use ISO 8601\n\nsingleDateTime\nrangeOfDates\n\nbeginDate\n\ncalendarDate\n\nendDate\n\ncalendarDate\n\n\n\ntaxonomicCoverage: taxonomic information about the dataset. It can include a species list.\n\ngeneralTaxonomicCoverage\ntaxonomicClassification\n\ntaxonRankName\ntaxonRankValue\ncommonName\n\n\n\nintellectualRights: Statement about IPR, Copyright or various Property Rights. Also read the guidelines on the sharing and use of data in OBIS.\n\npara\n\npurpose: A description of the purpose of this dataset.\n\npara\n\nmethods\n\nmethodStep: Descriptions of procedures, relevant literature, software, instrumentation, source data and any quality control measures taken.\nsampling: Description of sampling procedures including the geographic, temporal and taxonomic coverage of the study.\nstudyExtent: Description of the specific sampling area, the sampling frequency (temporal boundaries, frequency of occurrence), and groups of living organisms sampled (taxonomic coverage).\nsamplingDescription: Description of sampling procedures, similar to the one found in the methods section of a journal article.\n\npara\n\nqualityControl: Description of actions taken to either control or assess the quality of data resulting from the associated method step.\n\nproject\n\ntitle\nidentifier\npersonnel: The personnel field is used to document people involved in a research project by providing contact information and their role in the project.\ndescription\nfunding: The funding field is used to provide information about funding sources for the project such as: grant and contract numbers; names and addresses of funding sources.\n\npara\n\nstudyAreaDescription\ndesignDescription: The description of research design.\n\nmaintenance\n\ndescription\n\npara\n\nmaintenanceUpdateFrequency\n\nadditionalMetadata\n\nmetadata\n\ndateStamp: The dateTime the metadata document was created or modified (ISO 8601).\nmetadataLanguage: The language in which the metadata document (as opposed to the resource being described by the metadata) is written\nhierarchyLevel\n\ncitation : A single citation for use when citing the dataset. The IPT can also auto-generate a citation based on the metadata (people, title, organization, onlineURL, DOI etc).\nbibliography: A list of citations that form a bibliography on literature related / used in the dataset\nresourceLogoUrl: URL of the logo associated with a dataset.\nparentCollectionIdentifier\ncollectionIdentifier\nformationPeriod: Text description of the time period during which the collection was assembled. E.g., “Victorian”, or “1922 - 1932”, or “c. 1750”.\nlivingTimePeriod: Time period during which biological material was alive (for palaeontological collections).\nspecimenPreservationMethod\nphysical\n\nobjectName\ncharacterEncoding\ndataFormat\n\nexternallyDefinedFormat\nformatName\n\ndistribution: URL links\n\nonline\n\nurl function=\"download\"\nurl function=\"information\"\n\n\n\n\n\n\nalternateIdentifier: It is a Universally Unique Identifier (UUID) for the EML document and not for the dataset. This term is optional.\n\n\n2.4.4.1 Metadata Sections\nThere are several categories/pages for metadata you must provide, which includes basic information about the:\n\nDataset and data provider\nGeographic/taxonomic/temporal coverage\nKeywords\nHosting institution information\nInformation regarding associated project(s)\nSampling methods\nHow to cite the dataset\nMuseum collection (if applicable)\nOther external links (e.g. a homepage) or additional metadata\n\nWe review each of these sections below.\n\n2.4.4.1.1 Title\nThe IPT requires you to provide a Shortname. Shortnames serve as an identifier for the resource within the IPT installation (so should be unique within your IPT), and will be used as a parameter in the URL to access the resource via the Internet. Please use only alphanumeric characters, hyphens, or underscores. E.g. largenet_im in http://ipt.vliz.be/eurobis/resource?r=largenet_im. After creating a new dataset resource, the field title will be filled out with the short name you provided earlier. Please make sure you provide a dataset title following the guidelines below.\nDataset titles provided to OBIS node managers are often very cryptic, such as an acronym, and often only understandable by the data provider. However, to increase the discoverability and be useful for a larger audience, the dataset title should be as descriptive and complete as possible. OBIS recommends titles to contain information about the taxonomic, geographic and temporal coverage. If the dataset title does not meet these criteria and you believe the title should be changed, then contact the data provider with a suggestion or ask for a more descriptive title. If the dataset has already been published (made publicly available) - and therefore known by that title elsewhere, then the same title should be kept (even if it would not meet the proposed guidelines)! Changing the title of an already published dataset cannot be done, as this will generate confusion and possible duplicates in systems like OBIS or GBIF in a later stage.\nThe acronym or working title could still be documented in the metadata, so there is no confusion about how the full title is linked to the originally provided acronym or working title.\n\nCaution: Always consult the data provider when changing a dataset title to a more workable and descriptive version.\n\n\n\n\n\n\n\n\nOriginally received title\nTitle Recommended by Node Manager\n\n\n\n\nBIOCEAN\nBIOCEAN database on deep sea benthic fauna\n\n\nBiomôr\nBenthic data from the Southern Irish Sea from 1989-1991\n\n\nKyklades\nZoobenthos of the Kyklades (Aegean Sea)\n\n\nREPHY\nRéseau de Surveillance phytoplanctonique\n\n\n\n\n\n2.4.4.1.2 Abstract\nThe abstract or description of a dataset provides basic information on the content of the dataset. The information in the abstract should improve understanding and interpretation of the data. It is recommended that the description indicates whether the dataset is a subset of a larger dataset and – if so – provide a link to the parent metadata and/or dataset.\nIf the data provider or OBIS node require bi- or multilingual entries for the description (e.g. due to national obligations) then the following procedure can be followed:\n\nIndicate English as metadata language\nEnter the English description first\nType a slash (/)\nEnter the description in the second language\n\nExample: The Louis-Marie herbarium grants a priority to the Arctic-alpine, subarctic and boreal species from the province of Quebec and the northern hemisphere. This dataset is mainly populated with specimens from the province of Quebec. / L’Herbier Louis-Marie accorde une priorité aux espèces arctiques-alpines, subarctiques et boréales du Québec, du Canada et de l’hémisphère nord. Ce jeu présente principalement des spécimens provenant du Québec.\n\n\n2.4.4.1.3 People and Organizations\nThe EML has several possible roles/functions to describe a contact, creator, metadata provider and associated party.\nThe contact is the person or organization that curates the resource and who should be contacted to get more information or to whom questions with the resource or data should be addressed. Although a number of fields are not required, we strongly recommend providing as much information as possible, and in particular the email address. This will also be the contact information that appears on the OBIS metadata pages.\nThe creator is the person or organization responsible for the original creation of the resource content. When there are multiple creators, the one that bears the greatest responsibility is the resource creator, and other people can be added as associated parties with a role such as ‘originator’, ‘content provider’, ‘principal investigator’, etc.\nPossible functions/roles:\n\nOriginator (person/organization that originally gathered/prepared the dataset)\nContent provider (principal person/organization that contributed content to the dataset)\n\nIf the resource contact and the resource creator are identical, the IPT allows you to easily copy the information.\nThe metadata provider is the person or organization responsible for producing the resource metadata. If the metadata are provided by the original data provider, then his/her contact details should be filled in. If no metadata are available (e.g. for historical datasets, with no contact person), then the metadata can be completed by e.g. the OBIS node manager and the OBIS node manager becomes the metadata provider.\nThe Associated Parties contains information about one or more people or organizations associated with the resource in addition to those already covered on the IPT Basic Metadata page. For example, if there would be multiple contact persons or metadata creators, they can be added in this IPT section. The principal contact/creator should, however, be added in the IPT Basic Metadata section, not the Associated Parties section. It is recommended to complete this section together with the IPT Basic Metadata page, to avoid confusion or overlap in added information.\nPossible functions/roles for associated parties are:\n\nCustodian steward (person/organization responsible for/takes care of the dataset paper)\nOwner (person/organization that owns the data – may or may not be the custodian)\nPoint of contact (person/organization to contact for further information on the dataset)\nprincipal investigator (primary scientific contact associated with the dataset)\n\nNotes:\nThe owner of a dataset will, in most cases, be an institute, and not an individual person. Although the fields ‘last name’, and ‘position’ are indicated as mandatory fields, it is possible to just add the institute name in the ‘last name’ field for the role ‘owner’.\nThe contact persons in the metadata (contact, creator, metadata creator) are used in the dataset citation (auto-generation) and those added as ‘associated parties’ are not included as “co-authors”.\n\n\n2.4.4.1.4 License and IP Rights\nOBIS has published its guidelines on the sharing and use of data here. The recommended licenses for datasets published in OBIS are the Creative Commons Licenses (CC-0, CC-BY, CC-BY-NC), of which CC-0 is the most preferred and CC-BY-NC is least preferred. A Creative Commons license means:\n\nYou are free:\n\nto share =&gt; to copy, distribute and use the database\nto create =&gt; to produce works from the database\nto adapt =&gt; to modify, transform and build upon the database\n\n\nIn case of CC-0: public domain: CC-0 is the preferred option identified by the OBIS steering group. You waive any copyright you might have over the data(set) and dedicate it to the public domain. You cannot be held liable for any (mis)use of the data either. Although CC-0 doesn’t legally require users of the data to cite the source, it does not take away the moral responsibility to give attribution, as is common in scientific research. A good blog on why using CC-0 can be found here.\nIn case of CC-BY: Attribution: You must attribute any public use of the database, or works produced from the database, in the manner specified in the license. For any use or redistribution of the database, or works produced from it, you must make clear to others the license of the database and keep intact any notices on the original database.\nIn case of CC-BY-NC: non-commercial: like CC-BY but commercial use is not allowed. This licence can be problematic when the data is re-used in scientific journals.\n\n\n2.4.4.1.5 Coverage\n\n2.4.4.1.5.1 Geographic Coverage\nThe IPT allows you to enter the geographic coverage by dragging the markers on the given map or by filling in the coordinates of the bounding box. In the description field, a more elaborate text can be provided to describe the spatial coverage indicating the larger geographical area where the samples were collected. For the latter, the sampling locations can be plotted on a map and – by making use of a Gazetteer – the wider geographical area can be derived: e.g. the relevant Exclusive Economic Zone (EEZ), IHO, FAO fishing area, Large Marine Ecosystem (LME), Marine Ecoregions of the World (MEOW), etc. The Marine Regions’ Gazetteer might prove to be a useful online tool to define the most relevant sea area(s). There are also LifeWatch Geographical Services that translate geographical positions to these wider geographical areas.\nThe information given in this section can also help the OBIS node manager in geographic quality control. If the geographic coverage in the EML e.g. is “North Sea”, but a number of data points are outside of this scope, then this may indicate errors, and should be checked with the data provider.\nIf the dataset covers multiple areas (e.g. samples from the North Sea and the Mediterranean Sea), then this should clearly be mentioned in the geographicDescription field. Note that the IPT only allows one bounding box, and you have to uncheck the “Set global coverage” box to change box bounds.\n\n\n\nScreenshot of the Geographical Coverage section of the metadata, emphasizing how to change the bounds of the coverage box in the map.\n\n\n\n\n2.4.4.1.5.2 Taxonomic Coverage\nThis section can capture two things:\n\nA description of the range of taxa that are addressed in the data set. OBIS recommends to only add the higher classification (Kingdom, Class or Order) of the involved groups (e.g. Bivalvia, Cetacea, Aves, Ophiuroidea…). You can easily draw a list of higher taxonomic ranks from the WoRMS taxon match service (or ask the data provider). The taxonomic coverage is not a mandatory field, but the information stored here can be very useful as background information. The description can also contain common names, such as e.g. benthic foraminifera or mussels.\nAn overview of all the involved taxa (not recommended, as all the taxa are already listed in the dataset).\n\n\nNote: OBIS also recommends to add information on the (higher) taxonomic groups in the (descriptive) dataset title and abstract.\n\n\n\n\nExample of the Taxonomic Coverage section of the metadata\n\n\n\n\n2.4.4.1.5.3 Temporal Coverage\nThe temporal coverage will be a date range, which can easily be documented. If it is a single date, the start and end date will be the same. The information added here can be used as a quality check for the actual dates in the datasets.\nYou can also document the Formation Period or the Living Time Period in this section for specimens that may not have been alive during the collection period, or to indicate the time during which the collection occurred.\n\n\n\nExample of the Temporal Coverage section of the metadata\n\n\n\n\n\n2.4.4.1.6 Keywords\nRelevant keywords facilitate the discovery of a dataset. An indication of the represented functional groups can help in a general search (e.g. plankton, benthos, zooplankton, phytoplankton, macrobenthos, meiobenthos …). Assigned keywords can be related to taxonomy, habitat, geography or relevant keywords extracted from thesauri such as the ASFA thesaurus, the CAB thesaurus or GCMD keywords.\nAs taxonomy and geography are already covered in previous sections, there is no need to repeat related keywords here. Please consult your data provider which (relevant) keywords can be assigned.\n\n\n\nExample of the Keywords section of the metadata, showing input for a marine fishes dataset\n\n\n\n\n2.4.4.1.7 Project\nIf the dataset in this resource is produced under a certain project, the metadata on this project can be documented here. Part of the information entered here, can partly overlap with information given in other sections of the metadata (e.g. study area description can have lot of parallel with the geographic coverage section). Personnel involved in the project can be documented or repeated here as well. This is not a problem.\n\n\n2.4.4.1.8 Sampling Methods\nThe EML can contain descriptions of the sampling and data processing methods. Study extent can be documented here as well to report a more specific geographic area as well as the sampling frequency. Descriptions of sampling procedures, quality control, and steps (sample or data processing) can be given in the same way as the methods section of a scientific paper.\nNote that OBIS best practice is to add sampling facts to the extended MeasurementorFact extension, linked to the sampling events in the Event core via eventID.\n\n\n2.4.4.1.9 Citations\nThe dataset citation allows users to properly cite your dataset in further publications or other uses of the data. When users download datasets from the OBIS download function, a list of the dataset citations packaged with the data in a zipped file is provided.\nA dataset citation is different from the data source citation (in case the data is digitized from a publication), and these references can be added to the additional metadata (see bibliography below). A dataset citation can have the same format of a journal article citation, and should include the authors (contact, creator, principle investigator, data managers, custodians, collectors…), the title of the dataset, the name of the data publisher (or custodian institute), and the access point URL to the resource.\nGBIF’s IPT has an auto-generation - Turn On/Off - tool to let the IPT auto-generate the resource citation for you. The citation includes a version number, which is especially important for datasets that are continuously updated. The dataset citation can also include a Citation Identifier - a DOI, URI, or other persistent identifier that resolves to an online dataset web page.\nThe OBIS node data managers should try to implement a certain degree of format standardization for the dataset citations. The IPT provides an option to auto-generate a citation based on the EML and is formatted as follows: {dataset.authors} ({dataset.pubDate}) {dataset.title}. [Version {dataset.version}]. {organization.title}. {dataset.type} Dataset {dataset.doi}, {dataset.url}\n\n\n2.4.4.1.10 Bibliography\nThe EML can include the citation of the publications that are related to the described dataset. They can describe the dataset, be based on the dataset or be used in this dataset. Publications can be scientific papers, reports, PhD or master theses. If available, the citation should include the DOI at the end.\nThis overview will contribute to a better understanding of the data as these publications can hold important additional information on the data and how they were acquired.\n\n\n2.4.4.1.11 Collection Data\nThis IPT section should only be filled out if there are specimens held in a museum. If relevant, it is strongly recommended that this information is supplied by the data provider or left blank. The collection name, specimen preservation method, and curatorial units should be provided, as applicable.\n\n\n\nScreenshot of the Collection Data page showing what information can be provided for museum specimens\n\n\n\n\n2.4.4.1.12 External Links\nThis section can include URLs to the resource homepage, to download or find additional information. You can also provide links to your resource if it is hosted elsewhere in different formats.\nLinks to the online dataset on the OBIS website can be added once the data is available there. For these OBIS links, the required fields should be completed as follows:\n\nName: online dataset\nCharacter set: UTF-8\nData format: html\n\nIf other links are added, then the data format for web-based data is ‘html’. If the link refers to a file, the data format of the file will need to be added (e.g. .xlsx, .pdf …). The character set for all Darwin Core files is UTF-8, whereas for other web pages this can vary, so you may need to confirm.\n\n\n2.4.4.1.13 Additional Metadata\nAny remaining information that could not be catalogued under any of the other metadata, can be mentioned here. This may include logos, purpose of the dataset, a description of how the dataset will be maintained, etc."
  },
  {
    "objectID": "contribute.html#obis-nodes",
    "href": "contribute.html#obis-nodes",
    "title": "2  What can you contribute and how?",
    "section": "2.5 OBIS nodes",
    "text": "2.5 OBIS nodes\nNote the OBIS node TOR and system architecture is currently under review and will be updated after the 2023 Steering Group meeting. The information below may change.\nOBIS Nodes are either national projects, programmes, institutes, or organizations, National Ocean Data Centers or regional or international projects, programmes and institutions or organizations that carry out data management functions.\nOBIS nodes are responsible for representing all aspects of OBIS within a particular region or taxonomic domain. Additional responsibilities include:\n\nEstablishing relationships with key data providers within their geographical (or taxonomic) area of responsibility\nBringing data and corresponding metadata into the global database to be shared with the OBIS community\nResponsibility for all aspects of the data\nGaining permission to providing access to the data\nEnsuring a certain level of data quality\nTransfer of these datasets to the global OBIS database\nProvide support for the full implementation of OBIS worldwide by serving on the IODE Steering Group for OBIS and any relevant Task Teams or ad hoc project teams\nEach node may also maintain a data presence on the Internet representing their specific area of responsibility\n\n\n2.5.1 Terms of Reference of OBIS nodes\nData Responsibilities\n\nReceiving or harvesting marine biodiversity data (and metadata) from national, regional, and international programs, and the scientific community at large, and from Tier III nodes by Tier II nodes, and from Tier II nodes by Tier I nodes\nPerform data validation (using standards, tools, and best practices), as described in the OBIS manual (Tier II)\nReporting the results of quality control directly to data collectors/originator (or Tier III node) as part of the quality assurance activity\nMaking data (and metadata) available to OBIS using agreed upon standards and formats which are described in the OBIS Manual (Tier II), making data available to Tier II nodes (Tier III)\nControl data access, terms of use and sharing policies\nComply with the IOC/OBIS data policy for using and sharing OBIS data\nContribute to the development of standards and best practices in OBIS (recommended)\nContribute to the development of open-source tools in OBIS (recommended)\nEnsuring the long-term preservation of the data, metadata and associated information required for correct interpretation of the data (including version-control) (recommended)\nBuild customized data portals (optional)\n\nAdministration Responsibilities\n\nBecome a member of the IODE steering group for OBIS, attend the SG-OBIS annual meeting and report on node activities\nProvide indicators on up-time, responsiveness, and data processed by nodes and present a report to SG-OBIS\nCustomer support (data queries, analyses, feedback)\nOutreach and Capacity Building (i.e., providing expertise, training and support in data management, technologies, standards and best practices)\nEngage in stakeholder groups (recommended)\n\n\n\n2.5.2 How to become an OBIS node\nOBIS nodes now operate under the IODE network as either National Oceanographic Data Centres (NODCs) or Associate Data Unites (ADUs). Prospective nodes are required to apply to the IODE for membership.\nThe procedure to become an OBIS node is as follows:\n\nIf you are an existing NODC (within the IODE network) and the OBIS node activities fall under the activities of the NODC:\n\nSend a letter expressing your interest to become an OBIS node (including contact information of the OBIS node manager, and geographical/thematic scope of your OBIS node)\n\nIf you are not an existing NODC:\n\nEmail your application form to become an IODE Associate Data Unit (ADU), with a specific role as OBIS node. Applications for ADU membership in OBIS shall be reviewed by the IODE Officers in consultation with the IODE Steering Group for OBIS.\n\n\n\n\n2.5.3 OBIS Node Health Status Check and Transition Strategy\nOBIS nodes should operate under IODE as either IODE/ADU or IODE/NODC. As such OBIS nodes are a member of the IODE network.\nThe IODE Steering Group (SG) for OBIS evaluates the health status of OBIS nodes at each annual SG meeting, and considers an OBIS node as inactive when it meets any of the following conditions:\n\nThe OBIS node manager recurrently fails to answer the communications from the project manager or the SG co-chairs in the last 12 months\nThe OBIS node manager or a representative fails to attend (personally or virtually) the last 2 SG meetings without any written reason\nThe OBIS node does not have an IPT\nThe OBIS node has an IPT, but it has not been running for the last 12 months\nThe datasets in the OBIS node’s IPT have been removed and not restored in the last 12 months (without any explanation)\nThe OBIS node has not provided new data for the last 2 years\n\nThe OBIS Secretariat prepares a health status check report of each OBIS node based on the six items above and informs the OBIS node manager on their status 3 months before the SG meeting. At the SG meeting, the SG-OBIS co-chair will present the results of the OBIS nodes health status check report including a listing of the inactive OBIS nodes. The SG-OBIS members representing active OBIS Nodes will make one of the following decisions:\n\nRequest the inactive OBIS node to submit a plan with actions, deliverables and times to improve their performance, within 3 months, to the OBIS Secretariat. This plan is reviewed and accepted by the OBIS-Executive Committee Or\nProvide a recommendation to the IOC Committee on IODE to remove the OBIS node from the IODE network.\n\nIn either case, the OBIS Secretariat will inform the OBIS node manager of the SG-OBIS decision, with a copy to the IODE officers and the IODE national coordinator for data management of the country concerned.\nThe IODE Committee is requested to consider the recommendation from the OBIS Steering Group and it may either accept the recommendation or request the inactive OBIS node to submit an action plan (option 1).\nWhen the inactive OBIS node is removed from the IODE network, the SG-OBIS will ask whether another OBIS node is interested in taking over the responsibilities of the removed OBIS node, until a new OBIS node in the country/region is established."
  },
  {
    "objectID": "formatting.html#when-to-use-event-core",
    "href": "formatting.html#when-to-use-event-core",
    "title": "3  Dataset structure",
    "section": "3.1 When to use Event Core",
    "text": "3.1 When to use Event Core\nEvent Core describes when and where a specific sampling event happened and contains information such as location and date. Event Core is often used to organize your data tables when there are more than one sampling occasion and/or location, and different occurrences linked to each sampling. This organization follows the rationale of most ecological studies and typical marine sampling design. It covers:\n\nWhen specific details are known about how a biological sample was taken and processed. These details can then be defined in the eMoF Extension with the Q01 vocabulary\nWhen the dataset contains abiotic measurements, or other biological measurements which are related to an entire sample (not a single specimen). For example a biomass measurement for an entire sample, not each species within the sample\n\nEvent Core can be used in combination with the Occurrence and eMoF extensions. The identifier that links Event Core to the extension is the eventID. parentID can also be used to give information on hierarchical sampling. occurrenceID can also be used in datasets with Event Core in order to link information between the Occurrence extension and the eMoF extension."
  },
  {
    "objectID": "formatting.html#when-to-use-occurrence-core",
    "href": "formatting.html#when-to-use-occurrence-core",
    "title": "3  Dataset structure",
    "section": "3.2 When to use Occurrence Core",
    "text": "3.2 When to use Occurrence Core\nOccurrence Core datasets describe observations and specimen records and cover instances when:\n\nNo information on how the data was sampled or how samples were processed is available\nNo abiotic measurements are taken or provided\nYou have eDNA and DNA-derived data\nBiological measurements are made on individual specimens (each specimen is a single occurrence record)\n\nOccurrence Core is also often the preferred structure for museum collections, citations of occurrences from literature, and sampling activities.\nDatasets formatted in Occurrence Core can use the eMoF Extension for when you have biotic measurements or facts about your specimen. The DNA derived data extension can also be used to link to DNA sequences. The identifier that links Occurrence Core to the extension(s) is the occurrenceID."
  },
  {
    "objectID": "formatting.html#extensions-in-obis",
    "href": "formatting.html#extensions-in-obis",
    "title": "3  Dataset structure",
    "section": "3.3 Extensions in OBIS",
    "text": "3.3 Extensions in OBIS\nCurrently OBIS accepts the following extensions:\n\nOccurrence\nEvent\nMeasurementOrFact\nextendedMeasurementOrFact\nDNADerivedData\n\n\n3.3.1 How are extensions linked to core tables in OBIS?\nAs established in the relational database section, OBIS relies on datasets being formatted according to a relational database structure. The ENV-DATA approach that OBIS implements means your dataset will have a Core table and (optionally) Extension tables. As a review, a core file contains information relevant and applicable to each record in the extension(s). An extension file then contains records that link back to a record in the core file with more specific information (e.g., methods, measurements, facts, DNA sequences, etc.).\nThe extension file(s) accepted by OBIS (eMoF, Occurrence, DNA) are linked to your core tables by the use of identifying ID codes. These codes could be either eventID or occurrenceID. For details on how to construct these IDs, click here.\n\n\n3.3.2 Differences between identifiers\nIf your core file is based on occurrences (e.g., a record of one or more taxa specimens), then any extensions are linked with occurrenceID. If your core file is based on events (e.g., a sampling event, cruise, observation, etc.), then the linking identifier is eventID. In the Core tables, identifiers are always unique, which means, they do not repeat and each line has a different identifier. On the other hand, multiple records in an extension file can have the same identifier which will link them to the same event or occurrence record (depending on which is the Core). The different linking identifiers are shown in the figure below.\n\n\n\nDiagram of how the different core tables are linked to their extensions by different identifiers.\n\n\nLet us consider a fictional plankton trawl sampling event to demonstrate how identifiers link Core and Extension tables in OBIS. This trawl used two types of nets, occurred in March 2013, and has an eventID plankton-northsea-2013-03. Suppose we have information about the types of trawl used and the species abundance from this trawling event. The information (e.g., date) of the sampling event itself would be found in the Event Core, whereas the abundance data and sampling methods would be in the eMoF table. How do we ensure the abundance and sampling method data is properly linked to the correct event? By using the same eventID for each record in the eMoF table, plankton-northsea-2013-03, the information is properly linked between the Event Core and the eMoF extension."
  },
  {
    "objectID": "formatting.html#data-formatting-tools",
    "href": "formatting.html#data-formatting-tools",
    "title": "3  Dataset structure",
    "section": "3.4 Data formatting tools",
    "text": "3.4 Data formatting tools\nThe GBIF Norwegian Node created the DwC Excel Template Generator. This tool will generate four different types of blank Excel spreadsheets: Occurrence Core, MeasurementOrFact, Metadata, and a README. This tool works best if you already know which Darwin Core fields you need, although a default template can be generated.\nAnother tool from Norway is the Excel to Darwin Core Standard (DwC) Tool. This is a macro Excel spreadsheet that helps create templates for Event (aka Sampling-Event) and Occurrence core tables, as well as MeasurementsOrFacts, Extended MeasurementsOrFacts, and Simple Multimedia extensions. GBIF provides an Occurrence core template and an Event core template. If you use these templates from GBIF, be aware that GBIF’s required terms are different from OBIS.\nThere are also some tools that can help you unpivot (or flatten) data tables. These can be used to flatten many columns into one, particularly useful for the eMoF table.\n\nGBIF Norway’s crosstab to list converter. Note that this tool is not completely automated\nExcel’s built-in unpivot function"
  },
  {
    "objectID": "checklist.html#darwin-core-term-checklist-for-obis",
    "href": "checklist.html#darwin-core-term-checklist-for-obis",
    "title": "4  Formatting data tables",
    "section": "4.1 Darwin Core Term Checklist for OBIS",
    "text": "4.1 Darwin Core Term Checklist for OBIS\nThere are many Darwin Core terms listed in the TDWG quick reference guide. However, not all these terms are necessary for publishing data to OBIS.\nFor your convenience, we have created a checklist of all the Darwin Core terms relevant for OBIS data providers. You can reference this list to quickly see which terms are required by OBIS, which file (Event, Occurrence, eMoF, DNA) they can be found in, and which Darwin Core class it relates to. These terms correlate with the IPT vocabulary mapping you will do when it comes time to publish your dataset. You may notice some terms are accepted in multiple data tables (e.g., Event and Occurrence) - this is because it depends on your dataset structure. If you have an Event Core, you will include some terms that would not be included if you had Occurrence Core. For guidance on specific class terms (e.g., location, taxonomy, etc.), see the Darwin Core section of the manual.\nNote that when you publish your dataset on the IPT, if you use a term not listed below it will be an unmapped field and will not be published alongside your data. You may still wish to include such fields in your dataset if you are publishing to other repositories, just know that they will not be included in your OBIS dataset. You may include this information either by putting it in the dynamicProperties field in JSON format, or putting the information into the eMoF. Alternatively, you may have fields that you do not wish to be published and that do not correspond to one of these terms (e.g. personal notes). This is okay - if they are not mapped to one of the terms, that column in your dataset will not be published.\n\n\n\n\n\n\n\n\n\n\n\n\nTerm\nOBIS Required\nDarwinCore Class\nEvent\nOccurrence\neMoF\nDNA\n\n\n\n\neventDate\nrequired\nevent\nx\nx\n\n\n\n\neventID\nrequired\nevent\nx\nx\nx\n\n\n\ndecimalLatitude\nrequired\nlocation\nx\nx\n\n\n\n\ndecimalLongitude\nrequired\nlocation\nx\nx\n\n\n\n\noccurrenceID\nrequired\noccurrence\n\nx\nx\nx\n\n\noccurrenceStatus\nrequired\noccurrence\n\nx\n\n\n\n\nbasisOfRecord\nrequired\nrecord\n\nx\n\nx\n\n\nscientificName\nrequired\ntaxon\n\nx\n\n\n\n\nscientificNameID\nstrongly recommended\ntaxon\n\nx\n\n\n\n\nDNA_sequence\nstrongly recommended\ndna\n\n\n\nx\n\n\nenv_broad_scale\nstrongly recommended\ndna\n\n\n\nx\n\n\nenv_local scale\nrecommended\ndna\n\n\n\nx\n\n\nenv_medium\nstrongly recommended\ndna\n\n\n\nx\n\n\nlib_layout\nrecommended\ndna\n\n\n\nx\n\n\nnucl_acid_amp\nrecommended\ndna\n\n\n\nx\n\n\nnucl_acid_ext\nrecommended\ndna\n\n\n\nx\n\n\notu_class_appr\nrecommended\ndna\n\n\n\nx\n\n\notu_db\nrecommended\ndna\n\n\n\nx\n\n\notu_seq_comp_appr\nrecommended\ndna\n\n\n\nx\n\n\npcr_primer_forward\nstrongly recommended\ndna\n\n\n\nx\n\n\npcr_primer_name_forward\nstrongly recommended\ndna\n\n\n\nx\n\n\npcr_primer_name_reverse\nstrongly recommended\ndna\n\n\n\nx\n\n\npcr_primer_reference\nstrongly recommended\ndna\n\n\n\nx\n\n\npcr_primer_reverse\nstrongly recommended\ndna\n\n\n\nx\n\n\nsamp_name\nrecommended\ndna\n\n\n\nx\n\n\nsamp_vol_we_dna_ext\nrecommended\ndna\n\n\n\nx\n\n\nseq_meth\nrecommended\ndna\n\n\n\nx\n\n\nsop\nrecommended\ndna\n\n\n\nx\n\n\ntarget_gene\nstrongly recommended\ndna\n\n\n\nx\n\n\ntarget_subfragment\nstrongly recommended\ndna\n\n\n\nx\n\n\nday\nrecommended\nevent\nx\nx\n\n\n\n\nendDayOfYear\nrecommended\nevent\nx\nx\n\n\n\n\neventRemarks\noptional\nevent\nx\nx\n\n\n\n\neventTime\nrecommended\nevent\nx\nx\n\n\n\n\nfieldNotes\noptional\nevent\nx\n\n\n\n\n\nfieldNumber\noptional\nevent\nx\n\n\n\n\n\nhabitat\nrecommended\nevent\nx\n\nx\n\n\n\nmonth\nstrongly recommended\nevent\nx\nx\n\n\n\n\nparentEventID\nrequired (if exists)\nevent\nx\n\n\n\n\n\nsampleSizeUnit\nstrongly recommended\nevent\n\nx\nx\n\n\n\nsampleSizeValue\nstrongly recommended\nevent\n\nx\nx\n\n\n\nsamplingEffort\nstrongly recommended\nevent\n\nx\nx\n\n\n\nsamplingProtocol\nstrongly recommended\nevent\n\nx\nx\n\n\n\nstartDayOfYear\nrecommended\nevent\nx\n\n\n\n\n\nverbatimEventDate\nrecommended\nevent\nx\n\n\n\n\n\nyear\nstrongly recommended\nevent\nx\nx\n\n\n\n\nbed\noptional\ngeologicalContext\nx\nx\n\n\n\n\nearliestAgeOrLowestStage\noptional\ngeologicalContext\nx\nx\n\n\n\n\nearliestEonOrLowestEonothem\noptional\ngeologicalContext\nx\nx\n\n\n\n\nearliestEpochOrLowestSeries\noptional\ngeologicalContext\nx\nx\n\n\n\n\nearliestEraOrLowestErathem\noptional\ngeologicalContext\nx\nx\n\n\n\n\nearliestPeriodOrLowestSystem\noptional\ngeologicalContext\nx\nx\n\n\n\n\nformation\noptional\ngeologicalContext\nx\nx\n\n\n\n\ngroup\noptional\ngeologicalContext\nx\nx\n\n\n\n\nhighestBiostratigraphicZone\noptional\ngeologicalContext\nx\nx\n\n\n\n\nlatestAgeOrHighestStage\noptional\ngeologicalContext\nx\nx\n\n\n\n\nlatestEonOrHighestEonothem\noptional\ngeologicalContext\nx\nx\n\n\n\n\nlatestEpochOrHighestSeries\noptional\ngeologicalContext\nx\nx\n\n\n\n\nlatestEraOrHighestErathem\noptional\ngeologicalContext\nx\nx\n\n\n\n\nlatestPeriodOrHighestSystem\noptional\ngeologicalContext\nx\nx\n\n\n\n\nlithostratigraphicTerms\noptional\ngeologicalContext\nx\nx\n\n\n\n\nlowestBiostratigraphicZone\noptional\ngeologicalContext\nx\nx\n\n\n\n\nmember\noptional\ngeologicalContext\nx\nx\n\n\n\n\ndateIdentified\noptional\nidentification\n\nx\n\n\n\n\nidentificationID\noptional\nidentification\n\nx\n\n\n\n\nidentificationQualifier\nrecommended\nidentification\n\nx\n\n\n\n\nidentificationReferences\noptional (required for imaging data)\nidentification\n\nx\n\n\n\n\nidentificationRemarks\nrecommended\nidentification\n\nx\n\n\n\n\nidentificationVerificationStatus\noptional (required for imaging data)\nidentification\n\nx\n\n\n\n\nidentifiedBy\noptional (required for imaging data)\nidentification\n\nx\n\n\n\n\nidentifiedByID\noptional\nidentification\n\nx\n\n\n\n\ntypeStatus\noptional\nidentification\n\nx\n\n\n\n\ncontinent\nstrongly recommended\nlocation\nx\nx\n\n\n\n\ncoordinatePrecision\nstrongly recommended\nlocation\nx\nx\n\n\n\n\ncoordinateUncertaintyInMeters\nstrongly recommended\nlocation\nx\nx\n\n\n\n\ncountry\nrecommended\nlocation\nx\nx\n\n\n\n\ncountryCode\noptional\nlocation\nx\nx\n\n\n\n\ncounty\noptional\nlocation\nx\nx\n\n\n\n\nfootprintSpatialFit\noptional\nlocation\nx\nx\n\n\n\n\nfootprintSRS\noptional\nlocation\nx\nx\n\n\n\n\nfootprintWKT\nrecommended\nlocation\nx\nx\n\n\n\n\ngeodeticDatum\nrecommended\nlocation\nx\nx\n\n\n\n\ngeoreferencedBy\noptional\nlocation\nx\nx\n\n\n\n\ngeoreferencedDate\noptional\nlocation\nx\nx\n\n\n\n\ngeoreferenceProtocol\noptional\nlocation\nx\nx\n\n\n\n\ngeoreferenceSources\noptional\nlocation\nx\nx\n\n\n\n\nhigherGeography\noptional\nlocation\nx\nx\n\n\n\n\nhigherGeographyID\noptional\nlocation\nx\nx\n\n\n\n\nisland\noptional\nlocation\nx\nx\n\n\n\n\nislandGroup\noptional\nlocation\nx\nx\n\n\n\n\nlocality\nrecommended\nlocation\nx\nx\n\n\n\n\nlocationAccordingTo\nrecommended\nlocation\nx\nx\n\n\n\n\nlocationID\nstrongly recommended\nlocation\nx\nx\n\n\n\n\nlocationRemarks\nrecommended\nlocation\nx\nx\n\n\n\n\nmaximumDepthInMeters\nstrongly recommended\nlocation\nx\nx\n\n\n\n\nmaximumDistanceAboveSurfaceInMeters\noptional\nlocation\nx\nx\n\n\n\n\nmaximumElevationInMeters\noptional\nlocation\nx\nx\n\n\n\n\nminimumDepthInMeters\nstrongly recommended\nlocation\nx\nx\n\n\n\n\nminimumDistanceAboveSurfaceInMeters\noptional\nlocation\nx\nx\n\n\n\n\nminimumElevationInMeters\noptional\nlocation\nx\nx\n\n\n\n\nmunicipality\noptional\nlocation\nx\nx\n\n\n\n\npointRadiusSpatialFit\noptional\nlocation\nx\nx\n\n\n\n\nstateProvince\noptional\nlocation\nx\nx\n\n\n\n\nverbatimCoordinates\noptional\nlocation\nx\nx\n\n\n\n\nverbatimCoordinateSystem\noptional\nlocation\nx\nx\n\n\n\n\nverbatimDepth\noptional\nlocation\nx\nx\n\n\n\n\nverbatimElevation\noptional\nlocation\nx\nx\n\n\n\n\nverbatimLatitude\noptional\nlocation\nx\nx\n\n\n\n\nverbatimLocality\noptional\nlocation\nx\nx\n\n\n\n\nverbatimLongitude\noptional\nlocation\nx\nx\n\n\n\n\nverbatimSRS\noptional\nlocation\nx\nx\n\n\n\n\nwaterBody\nrecommended\nlocation\nx\nx\n\n\n\n\nmaterialSampleID\nrecommended\nmaterialSample\n\nx\n\n\n\n\nmeasurementAccuracy\nrecommended\nmeasurementOrFact\n\n\nx\n\n\n\nmeasurementDeterminedBy\noptional\nmeasurementOrFact\n\n\nx\n\n\n\nmeasurementDeterminedDate\noptional\nmeasurementOrFact\n\n\nx\n\n\n\nmeasurementID\nrecommended\nmeasurementOrFact\n\n\nx\n\n\n\nmeasurementMethod\nrecommended\nmeasurementOrFact\n\n\nx\n\n\n\nmeasurementRemarks\nrecommended\nmeasurementOrFact\n\n\nx\n\n\n\nmeasurementType\nstrongly recommended\nmeasurementOrFact\n\n\nx\n\n\n\nmeasurementTypeID\nstrongly recommended\nmeasurementOrFact\n\n\nx\n\n\n\nmeasurementUnit\nstrongly recommended\nmeasurementOrFact\n\n\nx\n\n\n\nmeasurementUnitID\nstrongly recommended\nmeasurementOrFact\n\n\nx\n\n\n\nmeasurementValue\nstrongly recommended\nmeasurementOrFact\n\n\nx\n\n\n\nmeasurementValueID\nstrongly recommended\nmeasurementOrFact\n\n\nx\n\n\n\nassociatedMedia\nrecommended\noccurrence\n\nx\n\n\n\n\nassociatedReferences\noptional\noccurrence\n\nx\n\n\n\n\nassociatedSequences\nrecommended\noccurrence\n\nx\n\n\n\n\nassociatedTaxa\noptional\noccurrence\n\nx\n\n\n\n\nbehavior\nrecommended\noccurrence\n\nx\nx\n\n\n\ncatalogNumber\nrecommended\noccurrence\n\nx\n\n\n\n\ndisposition\noptional\noccurrence\n\nx\n\n\n\n\nestablishmentMeans\noptional\noccurrence\n\nx\n\n\n\n\ngeoreferenceVerificationStatus\nrecommended\noccurrence\n\nx\n\n\n\n\nindividualCount\nstrongly recommended\noccurrence\n\nx\nx\n\n\n\nlifeStage\nrecommended\noccurrence\n\nx\nx\n\n\n\noccurrenceRemarks\nrecommended\noccurrence\n\nx\n\n\n\n\norganismQuantity\nstrongly recommended\noccurrence\n\nx\nx\n\n\n\norganismQuantityType\nstrongly recommended\noccurrence\n\nx\nx\n\n\n\notherCatalogNumbers\noptional\noccurrence\n\nx\n\n\n\n\npreparations\noptional\noccurrence\n\nx\n\n\n\n\nrecordedBy\nrecommended\noccurrence\n\nx\n\n\n\n\nrecordedByID\nrecommended\noccurrence\n\nx\n\n\n\n\nrecordNumber\nrecommended\noccurrence\n\nx\n\n\n\n\nreproductiveCondition\nrecommended\noccurrence\n\nx\n\n\n\n\nsex\nrecommended\noccurrence\n\nx\nx\n\n\n\nassociatedOccurrences\noptional\norgansim\n\nx\n\n\n\n\nassociatedOrganisms\noptional\norgansim\n\nx\n\n\n\n\norganismID\nrecommended\norgansim\n\nx\n\n\n\n\norganismName\nrecommended\norgansim\n\nx\n\n\n\n\norganismRemarks\nrecommended\norgansim\n\nx\n\n\n\n\norganismScope\noptional\norgansim\n\nx\n\n\n\n\npreviousIdentifications\nrecommended\norgansim\n\nx\n\n\n\n\naccessRights\nrecommended\nrecord\nx\nx\n\n\n\n\nbibliographicCitation\nrecommended\nrecord\nx\nx\n\n\n\n\ncollectionCode\noptional\nrecord\nx\nx\n\n\n\n\ncollectionID\noptional\nrecord\nx\nx\n\n\n\n\ndataGeneralizations\noptional\nrecord\nx\nx\n\n\n\n\ndatasetID\nrecommended\nrecord\nx\nx\n\n\n\n\ndatasetName\nrecommended\nrecord\nx\nx\n\n\n\n\ndynamicProperties\nrecommended\nrecord\nx\nx\n\n\n\n\ninformationWithheld\noptional\nrecord\nx\nx\n\n\n\n\ninstitutionCode\noptional\nrecord\nx\nx\n\n\n\n\ninstitutionID\noptional\nrecord\nx\nx\n\n\n\n\nlanguage\nrecommended\nrecord\nx\nx\n\n\n\n\nlicense\nrecommended\nrecord\nx\nx\n\n\n\n\nmodified\nrecommended\nrecord\nx\nx\n\n\n\n\nownerInstitutionCode\noptional\nrecord\nx\nx\n\n\n\n\nreferences\nrecommended\nrecord\nx\nx\n\n\n\n\nrightsHolder\nrecommended\nrecord\nx\nx\n\n\n\n\ntype\nstrongly recommended\nrecord\nx\nx\nx\n\n\n\nacceptedNameUsage\nrecommended\ntaxon\n\nx\n\n\n\n\nacceptedNameUsageID\nrecommended\ntaxon\n\nx\n\n\n\n\nhigherClassification\nrecommended\ntaxon\n\nx\n\n\n\n\ninfraspecificEpithet\nrecommended\ntaxon\n\nx\n\n\n\n\nnameAccordingToID\nrecommended\ntaxon\n\nx\n\n\n\n\nnamePublishedInID\noptional\ntaxon\n\nx\n\n\n\n\nnamePublishedInYear\noptional\ntaxon\n\nx\n\n\n\n\nnomenclaturalCode\noptional\ntaxon\n\nx\n\n\n\n\nnomenclaturalStatus\noptional\ntaxon\n\nx\n\n\n\n\noriginalNameUsage\nrecommended\ntaxon\n\nx\n\n\n\n\noriginalNameUsageID\nrecommended\ntaxon\n\nx\n\n\n\n\nparentNameUsage\nrecommended\ntaxon\n\nx\n\n\n\n\nparentNameUsageID\nrecommended\ntaxon\n\nx\n\n\n\n\nphylum\nrecommended\ntaxon\n\nx\n\n\n\n\nscientificNameAuthorship\nrecommended\ntaxon\n\nx\n\n\n\n\nspecificEpithet\nrecommended\ntaxon\n\nx\n\n\n\n\nsubgenus\nrecommended\ntaxon\n\nx\n\n\n\n\ntaxonConceptID\noptional\ntaxon\n\nx\n\n\n\n\ntaxonID\noptional\ntaxon\n\nx\n\n\n\n\ntaxonomicStatus\noptional\ntaxon\n\nx\n\n\n\n\ntaxonRank\nstrongly recommended\ntaxon\n\nx\n\n\n\n\ntaxonRemarks\nrecommended\ntaxon\n\nx\n\n\n\n\nverbatimTaxonRank\nrecommended\ntaxon\n\nx\n\n\n\n\nvernacularName\nrecommended\ntaxon\n\nx\n\n\n\n\ntype or eventType\nstrongly recommended\nevent\nx\n\n\n\n\n\nclass\nrecommended\ntaxon\n\nx\n\n\n\n\nfamily\nrecommended\ntaxon\n\nx\n\n\n\n\ngenus\nstrongly recommended\ntaxon\n\nx\n\n\n\n\nkingdom\nstrongly recommended\ntaxon\n\nx\n\n\n\n\norder\nstrongly recommended\ntaxon\n\nx"
  },
  {
    "objectID": "data_qc.html#why-are-records-dropped",
    "href": "data_qc.html#why-are-records-dropped",
    "title": "5  Data quality control",
    "section": "5.1 Why are records dropped?",
    "text": "5.1 Why are records dropped?\nRecords can be dropped and therefore not published with your dataset for a number of reasons, including:\n\nThe species is not marine\nThe ‘scientificName’ or scientificNameID did not match with WoRMS\nIssues with coordinates:\n\nNo coordinates given\ndecimalLatitude or decimalLongitude out of range\n\nThe coordinate is zero\n\nFor each dataset published, a quality report is generated where the number of dropped records and other quality issues will be flagged. Such reports can also be found when searching for data in OBIS. For example, if we searched for ‘Crustacea’ records, the following data quality report is given:\n\n\n\nNumber of Crustacean records dropped\n\n\nWe can see that &gt;110,222 Crustacean records have been dropped, mostly due to records missing coordinates or species being flagged as non-marine. Because species are determined as being marine by WoRMS, we acknowledge that sometimes species are marked as not_marine erroneously.For specific advice on this topic, see the common QC issues page.\nTo minimize the number of records dropped, be careful when formatting your data so that you are meeting the requirements."
  },
  {
    "objectID": "data_qc.html#how-to-conduct-quality-control",
    "href": "data_qc.html#how-to-conduct-quality-control",
    "title": "5  Data quality control",
    "section": "5.2 How to conduct Quality Control",
    "text": "5.2 How to conduct Quality Control\nOnce you have formatted your data for OBIS, or have received a formatted dataset, it is important to run quality control checks before publishing the dataset on the IPT. The following is a list of various tools you can use to help you perform quality checks on your data:\n\nR package obistools\nEMODnet Biocheck\n\nWeb UI built on obistools. This tool requires your dataset to be published on an IPT (e.g., a test IPT such as https://ipt.gbif.org/ where your dataset will not be harvested by GBIF or OBIS). Note you are required to have a login to access an IPT\nR package\n\nLifewatch data services\nThe US Integrated Ocean Observing System Standardizing Marine Bio Data Guide\nWoRMS taxon match tool\n\nOther WoRMS web services, incl. taxon match\n\nExcel Conditional Formatting tool\n\nExcel &gt; Home &gt; Conditional Formating &gt; Highlight cells Rules &gt; Duplicate values…\n\nGBIF data validator\nPython library for OBIS QC developed by Canadian Integrated Ocean Observing System\nR package and function Hmisc:: describe\n\nCan give important summary statistics and identify numbers that don’t match\n\n\n\n5.2.1 Conducting QC with obistools\nTo use obistools to conduct quality control, you can follow this general order:\n\nCheck that the taxa match with WoRMS\n\nobistools::match_taxa\n\nCheck that all required fields are present in the occurrence table\n\nobistools::check_fields\n\nCheck coordinates\n\nPlot them on a map to identify any points that appear outside the scope of the dataset obistools::plot_map\nIdentify points with obistools::identify_map\nCheck that points are not on land obistools::check_onland\nEnsure depth ranges are valid obistools::check_depth\n\nCheck for statistical outliers which may have had data entry errors\n\nobistools::check_outliers_species and obistools::check_outliers_dataset\n\nCheck that the eventID and parentEventID are structured correctly obistools::check_eventids\n\nEnsure all eventIDs in extensions have matching eventIDs in the core table obistools::check_extension_eventids\n\nCheck that eventDate is formatted properly obistools::check_eventdate\n\n\n\n5.2.2 QC with R package Hmisc\nThe R package Hmisc has the function describe which can help you identify any discrepancies in your dataset.\nIt will summarize each of your variables for a given data field. This can help you quickly identify any missing data and ensure the number of unique IDs is correct. For example, in an Occurrence table with 1000 records, there should be 1000 unique occurrenceIDs.\nlibrary(Hmisc)\nlibrary(Hmisc)\ndata&lt;-read.csv(\"example_data_occur.csv\")\ndescribe(data)\n \n 12  Variables      407  Observations\n------------------------------------------------------------------------------------------------------------------\nCollectionCode \n       n  missing distinct    value \n     407        0        1  BIOFUN1 \n                  \nValue      BIOFUN1\nFrequency      407\nProportion       1\n------------------------------------------------------------------------------------------------------------------\neventID \n       n  missing distinct \n     407        0       27 \n\nlowest : BIOFUN1_BF1A01 BIOFUN1_BF1A02 BIOFUN1_BF1A03 BIOFUN1_BF1A04 BIOFUN1_BF1A05\nhighest: BIOFUN1_BF1M3  BIOFUN1_BF1M4  BIOFUN1_BF1M6  BIOFUN1_BF1M8  BIOFUN1_BF1M9 \n------------------------------------------------------------------------------------------------------------------\noccurrenceID \n       n  missing distinct \n     407        0      407 \n\nlowest : CSIC_BIOFUN1_1   CSIC_BIOFUN1_10  CSIC_BIOFUN1_100 CSIC_BIOFUN1_101 CSIC_BIOFUN1_102\nhighest: CSIC_BIOFUN1_95  CSIC_BIOFUN1_96  CSIC_BIOFUN1_97  CSIC_BIOFUN1_98  CSIC_BIOFUN1_99 \nThis video shows how to use both obistools and Hmisc to conduct QC checks in R."
  },
  {
    "objectID": "data_publication.html#licenses",
    "href": "data_publication.html#licenses",
    "title": "6  Data publication and sharing",
    "section": "6.1 Licenses",
    "text": "6.1 Licenses\nOBIS nodes must make the necessary agreements with the original data providers so that data can be made available to OBIS under one of the following Creative Commons licenses (in order of preference):\n\nCC0 - data may be used without restrictions\nCC-BY - data are available for any use if proper attribution and credit is given\nCC-BY-NC - data may be used for any non-commercial use as long as proper attribution/credit is given\n\nYou may need to consult with your organization if there are any copyright concerns. For more information on the different Creative commons license types see About the licenses."
  },
  {
    "objectID": "access.html#obis-homepage-and-dataset-pages",
    "href": "access.html#obis-homepage-and-dataset-pages",
    "title": "7  Data access",
    "section": "7.1 OBIS Homepage and dataset pages",
    "text": "7.1 OBIS Homepage and dataset pages\nFrom the OBIS homepage, you can search for data in the search bar in the middle of the page. You can search by particular taxonomic groups, common names, dataset names, OBIS nodes, institute name, areas (e.g., Exclusive Economic Zone (EEZ)), or by the data provider’s country.\nWhen you search by dataset you will notice an additional option appears for advanced search options. This will allow you to identify specific datasets, and apply filters for OBIS nodes and whether datasets include extensions.\n\n\n\nOBIS homepage search, showing where to find the advanced search link\n\n\nRegardless if you found a dataset through the homepage or the advanced Dataset search, you will be able to navigate to individual dataset pages. For individual dataset pages (instead of aggregate pages for e.g., a Family) there are three buttons available:\n\nReport issue - allows you to report any issues with the dataset in question\nSource DwC-A - download the dataset as a Darwin Core-Archive file. This will provide all data tables as separate files within a zipped folder\nTo mapper - this will open another browser with the data shown in the Mapper\n\n\n\n\nDataset download\n\n\nIf you searched for aggregate datasets (e.g., all Crustacea records, all records from OBIS-Canada, etc.), the source DwC-A button will not be available to you. To download these data subsets, you must click to mapper and then download the data from the Mapper as a CSV."
  },
  {
    "objectID": "access.html#mapper",
    "href": "access.html#mapper",
    "title": "7  Data access",
    "section": "7.2 Mapper",
    "text": "7.2 Mapper\n\nhttps://mapper.obis.org\n\nWatch this video demonstration of how to use the Mapper as well as the OBIS homepage search.\n\nThe mapper allows users to visualize and inspect subsets of OBIS data. A variety of filters are available (taxonomic, geographic, time, data quality) and multiple layers can be combined in a single view. Layers can be downloaded as CSV files.\n\n\n\nScreenshot demonstrating where how to download a particular layer\n\n\nWhen you download data from the mapper, you will be given the option to include eMoF and/or DNA Derived Data extensions alongside the Event and Occurrence data. You must check the boxes of extensions you want to include in your download.\n\n\n\nScreenshot showing the popup confirmation for which extensions you want to include in your download from the OBIS Mapper\n\n\nAfter downloading, you will notice that the Event and Occurrence data is flattened into one table, called “Occurrence.csv”. Upon inspecting this file in your viewer of choice, you will see it contains all 225 possible DwC fields, although not every field will contain data for each observation. Any extensions you checked will be downloaded as separate tables."
  },
  {
    "objectID": "access.html#r-package",
    "href": "access.html#r-package",
    "title": "7  Data access",
    "section": "7.3 R package",
    "text": "7.3 R package\n\nhttps://github.com/iobis/robis\n\nThe robis R package has been developed to facilitate connecting to the OBIS API from R. The package can be installed from CRAN or from GitHub (latest development version). The package documentation includes a function reference as well as a getting started vignette. As a quick example of what the package can do, you can obtain raw occurrence data by feeding a taxon name or AphiaID to the occurrence function.\nIf you’d like to then download this data, you can simply export R objects with the write.csv function. For example, if we wanted to obtain Mollusc data from OBIS:\nlibrary(robis)\nmoll&lt;-occurrence(“Mollusca”)\nwrite.csv(moll, “mollusca-obis.csv”)\nThis file will be saved to your working directory (if you are not familiar with working directories, read here). After opening the file, you will notice that the fields in the download do not include every possible field, but instead only those where information has been recorded by data providers, plus the fields added by OBIS’s quality control pipeline.\nTo use robis for visualizing and mapping occurrences, see the Visualization section of the manual.\nWatch the video below for a walkthrough of how to use the robis package to obtain OBIS data."
  },
  {
    "objectID": "access.html#api",
    "href": "access.html#api",
    "title": "7  Data access",
    "section": "7.4 API",
    "text": "7.4 API\n\nhttps://api.obis.org/\n\nBoth the mapper and the R package are based on the OBIS API, which can also be used to find and download data. When using the API directly, you can filter by the following options:\n\nOccurrence\nTaxon\nChecklist\nNode\nDataset\nInstitute\nArea\nCountry\nFacet\nStatistics\n\nWhen you have entered all the information you are interested in filtering by, scroll down and click the “Execute” button. This will produce a response detailing how many records match your criteria, as well as information for some of the headers from the data (e.g., basisOfRecord, Order, genus, etc.). A download button will be available for you to download the data as well.\nWhen searching with the API, you may need to know certain identifiers, including:\n\nAphiaID - obtainable from the WoRMS page of a taxa of interest (e.g. the AphiaID for Mollusca would be 51)\nDataset UUID - can be obtained from the URL on individual dataset pages\n\nE.g., this dataset’s UUID would be 5061d21c-6161-4ea2-a8d4-38f8285dfc47\n\nArea ID\nInstitute ID - this should be the Ocean Expert ID (e.g., the ID for NOAA Fisheries Service, Southeast Regional Office St. Petersburg is 7532)\nOBIS node UUID\n\nA short video demonstrating use of the API is shown below."
  },
  {
    "objectID": "access.html#full-exports",
    "href": "access.html#full-exports",
    "title": "7  Data access",
    "section": "7.5 Full exports",
    "text": "7.5 Full exports\n\nhttps://obis.org/data/access/\n\nTo obtain a full export of OBIS data, navigate to the OBIS homepage, click on Data from the top navigation bar, then select Data Access from the dropdown menu.\n\n\n\nOBIS homepage showing where to navigate to access full database exports\n\n\nHere you will be able to download all occurrence records as a CSV or Parquet file. Note the disclaimer that such exports will not include measurement data, dropped records, or absence records. As with downloads from the Mapper, the exported file is a single Occurrence table. This table includes all provided Event and Occurrence data, as well as 68 fields added by the OBIS Quality Control Pipeline, including taxonomic information obtained from WoRMS.\n\n\n\nOBIS Data Access page"
  },
  {
    "objectID": "access.html#finding-your-own-data-in-obis",
    "href": "access.html#finding-your-own-data-in-obis",
    "title": "7  Data access",
    "section": "7.6 Finding your own data in OBIS",
    "text": "7.6 Finding your own data in OBIS\nTo find your own dataset in OBIS, you can use the same tools as finding any dataset in OBIS. You have the following options:\n\nFrom the OBIS homepage or the Mapper, you can search by dataset name, species of interest, the OBIS node that you uploaded to, or by institute\n\nNote: When using the Mapper you can combine multiple search criteria to help narrow down your search\n\nE.g., if we wanted to find this dataset in the Mapper, we could search for OBIS USA under Nodes, National Oceanic and Atmospheric Administration, Washington under Institutes, and/or Radiozoa under Scientific Name. Then when we view the data and scroll down to datasets, the only one listed is the one we were interested in\n\n\nIf you have used the (extended)measurementOrFact extension and have measurementType data, you can search by the name of your measurementType, click on the hyperlink for records. This will populate a list of datasets that you can scroll through."
  },
  {
    "objectID": "access.html#how-to-contact-data-provider",
    "href": "access.html#how-to-contact-data-provider",
    "title": "7  Data access",
    "section": "7.7 How to contact data provider",
    "text": "7.7 How to contact data provider\nTo contact the data provider, navigate to the page for the individual dataset in question (e.g., https://obis.org/dataset/80479e14-2730-436d-acaa-b63bdc7dd06f). Under the “Contacts” section, there will be a list of individuals you can contact. Clicking any name will direct you to your system’s default email program. For example:\n\n\n\nExample of contact section on a dataset homepage access via the OBIS search\n\n\nIf you are the node manager and need to contact the data provider about a particular dataset, contact information should be provided in the metadata and you can contact them from information provided."
  },
  {
    "objectID": "access.html#interpreting-downloaded-files-from-obis",
    "href": "access.html#interpreting-downloaded-files-from-obis",
    "title": "7  Data access",
    "section": "7.8 Interpreting downloaded files from OBIS",
    "text": "7.8 Interpreting downloaded files from OBIS\nIn general, the field names you will see when you download data from OBIS are the same as those seen during the data formatting and publishing process. When you download data from the Mapper you will see all 225 possible Darwin Core fields.\nDownloading data from an IPT or full export will include only the fields provided by the data provider, formatted as one Occurrence file (or separate files for individual datasets). Some fields are added through the OBIS quality control pipeline, including taxonomic information from WoRMS and the fields flags, bathymetry, and dropped. As mentioned in the Quality Control section, the fields flags and dropped will list quality control issues or if the record was dropped, respectively. Details and definitions for all fields added by the OBIS QC pipeline can be found here.\nFor a full list of the other Darwin Core terms and their definitions included in downloads, please reference the Darwin Core reference guide."
  },
  {
    "objectID": "dataviz.html#example-notebooks-using-data-from-obis",
    "href": "dataviz.html#example-notebooks-using-data-from-obis",
    "title": "8  Data Visualization",
    "section": "8.1 Example notebooks using data from OBIS",
    "text": "8.1 Example notebooks using data from OBIS\nHere are a few R notebooks showcasing the robis package:\n\nData exploration of wind farm monitoring datasets in OBIS\nDiversity of fish and vulnerable species in Marine World Heritage Sites based on OBIS data\nData exploration - Stratified random surveys (StRS) of reef fish in the U.S. Pacific Islands\nDNADerivedData extension data access\nCanary Current LME\n\nHere are others that may be of interest:\n\nDiversity indicators using OBIS data\nOBIS species richness for OSPAR\nQuality control of ISA data\nAccessing gridded data"
  },
  {
    "objectID": "dataviz.html#obisindicators-calculating-visualizing-spatial-biodiversity-using-data-from-obis",
    "href": "dataviz.html#obisindicators-calculating-visualizing-spatial-biodiversity-using-data-from-obis",
    "title": "8  Data Visualization",
    "section": "8.2 obisindicators: calculating & visualizing spatial biodiversity using data from OBIS",
    "text": "8.2 obisindicators: calculating & visualizing spatial biodiversity using data from OBIS\nobisindicators is an R library developed during the 2022 IOOS Code Sprint. The purpose was to create an ES50 diversity index within hexagonal grids following the diversity indicators notebook by Pieter Provoost linked above. The package includes several examples, limited to 1M occurrences, that demonstrate uses of the package.\n\n\n\nscreenshot"
  },
  {
    "objectID": "other_resources.html#mbon-pole-to-pole-tutorial",
    "href": "other_resources.html#mbon-pole-to-pole-tutorial",
    "title": "9  Other Resources",
    "section": "9.1 MBON Pole to Pole Tutorial",
    "text": "9.1 MBON Pole to Pole Tutorial\n\nhttps://www.youtube.com/watch?v=teJhfsSWonE\n\nThis tutorial was created by the MBON Pole to Pole project to help guide people through the process of transforming datasets to Darwin Core using tools MBON Pole to Pole has developed."
  },
  {
    "objectID": "other_resources.html#ioos-darwin-core-guide",
    "href": "other_resources.html#ioos-darwin-core-guide",
    "title": "9  Other Resources",
    "section": "9.2 IOOS Darwin Core Guide",
    "text": "9.2 IOOS Darwin Core Guide\n\nhttps://ioos.github.io/bio_data_guide/\n\nThis book contains a collection of examples and resources related to mobilizing marine biological data to the Darwin Core standard for sharing though OBIS. This book has been developed by the Standardizing Marine Biological Data Working Group (SMBD). The working group is an open community of practitioners, experts, and scientists looking to learn and educate the community on standardizing and sharing marine biological data."
  },
  {
    "objectID": "other_resources.html#emodnet-biology",
    "href": "other_resources.html#emodnet-biology",
    "title": "9  Other Resources",
    "section": "9.3 EMODnet Biology",
    "text": "9.3 EMODnet Biology\n\nhttps://classroom.oceanteacher.org/course/view.php?id=430\n\nContributing Datasets to EMODnet Biology is a course hosted on Ocean Teacher Global Academy (OTGA), developed by members of the European Marine Observation and Data Network. The course prepares users to format, publish, and perform quality control checks on datasets according to Darwin Core standards. While targeted at EMODnet Biology users, this course has significant overlap in how to prepare datasets for OBIS and is useful for those unfamiliar with OBIS standards. Note, an account with OTGA is required to access the course."
  },
  {
    "objectID": "other_resources.html#template-generators",
    "href": "other_resources.html#template-generators",
    "title": "9  Other Resources",
    "section": "9.4 Template Generators",
    "text": "9.4 Template Generators\nThere is an Excel template generator developed by Luke Marsden & Olaf Schneider as part of the Nansen Legacy project. It allows the creation of Event or Occurrence core templates, with an optional eMoF extension. Note this template generator is aimed at GBIF users, so make sure to account for and include required OBIS terms.\nThere is also an Excel to Darwin Core macro tool developed by GBIF Norway that you can download for use in Microsoft Excel. This macro can help you set up Event, Occurrence, and eMoF tables by selecting all relevant DwC fields from a list, or by importing data from another spreadsheet. It allows for auto-generation of identifiers (e.g. eventID, occurrenceID) if macros are enabled, and can also auto-populate the eMoF when measurement fields in the Occurrence table are populated."
  },
  {
    "objectID": "packages.html",
    "href": "packages.html",
    "title": "Packages",
    "section": "",
    "text": "Python packages\n\n\nEnable the download of data from OBIS\n\n\n\n\n\n\n\n\n\n\n\nR packages\n\n\nEnable the download of data from OBIS\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "packages/r/index.html",
    "href": "packages/r/index.html",
    "title": "R packages",
    "section": "",
    "text": "robis\nrobis, our flagship R package, is a client for the OBIS API. It includes functions for data access, as well as a few helper functions for visualizing occurrence data and extracting nested MeasurementOrFact or DNADerivedData records.\nAvailable through CRAN (use install.packages(“robis”)) GitHub: https://github.com/iobis/robis"
  },
  {
    "objectID": "tutorials.html",
    "href": "tutorials.html",
    "title": "Tutorials",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nUsing the Parquet format with OBIS data\n\n\n\n\n\nWorking with large datasets can be hard due to memory constraints, but using Parquet files can make it possible.\n\n\n\n\n\n\nAug 1, 2023\n\n\nSilas Principe\n\n\n4 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "OBIS Manual",
    "section": "",
    "text": "Making better use of OBIS data\nOBIS is not just a repository for biodiversity data. It’s also a community of practice that want to leverage the use of ocean biodiversity data. Here you will find tutorials and tools to help you make better use of data from OBIS (and other resources).\nYou can contribute with tutorials following the guidelines available at our repository.\nDon’t know where to start? We suggest reading the OBIS manual where you will find the most complete guide about how OBIS works and the different types of data available.\nCheck also the available packages and pipelines for R and other languages, and our tool to find the right Darwin Core schema for your data."
  },
  {
    "objectID": "find-dwc.html",
    "href": "find-dwc.html",
    "title": "Find your DwC",
    "section": "",
    "text": "Darwin Core (DwC) is a body of standards (i.e., identifiers, labels, definitions) that facilitate sharing biodiversity informatics. It provides stable terms and vocabularies related to biological objects/data and their collection.\nDwC is meant to be used from the beginning of your research and is an excellent way of organizing and standardizing your data. All data submitted to OBIS must follow the Darwin Core guidelines. Whether you are planning your project or preparing to submit your data to an OBIS node, a key question is on what type of structure your data fits and what DwC terms are relevant (and necessary). Considering that, we prepared this quick tool to explore the option most suited to your case.\nYou may also want to explore our extensive documentation in the OBIS manual, which provide more in-depth details, or this quick decision tree created by Elizabeth Lawrence.\n\nFinding my schema\n\n  \n  \n  \n  \n  \n  \n\n  \n  \n    \n      What kind of data do you have, or will collect?\n       Occurrence\n       Abundance/Percent cover\n       Biomass\n       Habitat\n       Tracking\n       Genetic\n    \n    \n    \n    \n    \n    \n      \n      You don't have genetic data ⇢\n      Will this be a recurring sampling event OR can you aggregate your data in a single event?\n      A recurring sampling is any sampling that will occur in more than one time step. You can also have a single sampling, but have information that is relative to all your data (e.g. all collected on the same place). Note that many datasets can possibly be grouped in an event.\n             Yes\n       No\n    \n\n    \n    \n      \n      You don't have genetic data ⇢\n      This will be a recurring event or can be aggregated into an event ⇢\n      Have (or will) you collect any data associated with samples or sampling?\n      Examples of associated data are temperature, length of specimen, etc.\n             Yes\n       No\n    \n\n    \n    \n      \n      You don't have genetic data ⇢\n      This will be a recurring event or can be aggregated into an event ⇢\n      You collected associated data ⇢\n      \n      + You will also need:\n      \n    \n\n    \n    \n      \n      You don't have genetic data ⇢\n      This will be a recurring event or can be aggregated into an event ⇢\n      You have not collected associated data ⇢\n      \n    \n\n    \n    \n      \n      You don't have genetic data ⇢\n      This will not be a recurring event or can't be aggregated into an event ⇢\n      Have (or will) you collect any data associated with samples or sampling?\n      Examples of associated data are temperature, length of specimen, etc.\n             Yes\n       No\n    \n\n    \n    \n      \n      You don't have genetic data ⇢\n      This will not be a recurring event or can't be aggregated into an event ⇢\n      You collected associated data ⇢\n      \n      + You will also need:\n      \n    \n\n    \n    \n      \n      You don't have genetic data ⇢\n      This will not be a recurring event or can't be aggregated into an event ⇢\n      You have not collected associated data ⇢\n      \n    \n\n    \n    \n    \n    \n      \n      You have genetic data ⇢\n      Have (or will) you collect any data associated with samples or sampling?\n      Examples of associated data are temperature, length of specimen, etc.\n             Yes\n       No\n    \n    \n    \n    \n      \n      You have genetic data ⇢\n      You collected associated data ⇢\n      \n      + You will also need:\n      \n      \n      \n    \n\n    \n    \n      \n      You have genetic data ⇢\n      You have not collected associated data ⇢\n      \n      + You will also need:\n      \n    \n    \n    \n    \n    Restart"
  },
  {
    "objectID": "packages/python/index.html",
    "href": "packages/python/index.html",
    "title": "Python packages",
    "section": "",
    "text": "robis\nrobis, our flagship R package, is a client for the OBIS API. It includes functions for data access, as well as a few helper functions for visualizing occurrence data and extracting nested MeasurementOrFact or DNADerivedData records.\nAvailable through CRAN (use install.packages(“robis”)) GitHub: https://github.com/iobis/robis"
  },
  {
    "objectID": "tutorials/arrow-obis-2023-09-08/index.html",
    "href": "tutorials/arrow-obis-2023-09-08/index.html",
    "title": "Using the Parquet format with OBIS data",
    "section": "",
    "text": "What is Parquet?\nParquet is a lightweight format designed for columnar storage. Its main difference when compared to other formats like csv is that Parquet is column-oriented (while csv is row-oriented). This means that Parquet is much more efficient for data accessing.To illustrate, consider the scenario of extracting data from a specific column in a CSV file. This operation entails reading through all rows across all columns. In contrast, Parquet enables selective access solely to the required column, minimizing unnecessary data retrieval. Also very important: Parquet files are several times lighter than csv files, improving storage and sharing of data. You can learn more about Parquet here.\n\n\n\nimage 1\n\n\nThe Arrow package enable to work with Parquet files (as well some other interesting formats) within R. You can read the full documentation of the package here.\nWe will now see how you can use Parquet in your data analysis workflow. Note that the real advantage of Parquet comes when working with large datasets, specially those that you can’t load into memory.\n\n\nReading and writing Parquet files\nOpening a Parquet file is similar to opening a csv, and is done through the function read_parquet. We will start working with a small dataset containing records from OBIS for a fiddler crab species (Leptuca thayeri) which you can download here.\n\nlibrary(arrow) # To open the parquet files\nlibrary(dplyr) # For data manipulation\n\nspecies &lt;- read_parquet(\"leptuca_thayeri.parquet\")\n\nhead(species)\n\n# A tibble: 6 × 127\n  basisOfRecord     class       continent country countryCode county datasetName\n  &lt;chr&gt;             &lt;chr&gt;       &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;       &lt;chr&gt;  &lt;chr&gt;      \n1 HumanObservation  Malacostra… América … Colomb… CO          San A… Epifauna m…\n2 HumanObservation  Malacostra… América … Colomb… CO          San A… Epifauna m…\n3 PreservedSpecimen Malacostra… &lt;NA&gt;      Brazil  &lt;NA&gt;        Paran… &lt;NA&gt;       \n4 HumanObservation  Malacostra… América … Colomb… CO          San A… Epifauna m…\n5 HumanObservation  Malacostra… América … Colomb… CO          San A… Epifauna m…\n6 HumanObservation  Malacostra… América … Colomb… CO          San A… Epifauna m…\n# ℹ 120 more variables: dateIdentified &lt;chr&gt;, day &lt;chr&gt;, decimalLatitude &lt;dbl&gt;,\n#   decimalLongitude &lt;dbl&gt;, establishmentMeans &lt;chr&gt;, eventDate &lt;chr&gt;,\n#   eventID &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;, geodeticDatum &lt;chr&gt;,\n#   georeferenceVerificationStatus &lt;chr&gt;, georeferencedBy &lt;chr&gt;,\n#   georeferencedDate &lt;chr&gt;, habitat &lt;chr&gt;, higherClassification &lt;chr&gt;,\n#   identifiedBy &lt;chr&gt;, identifiedByID &lt;chr&gt;, institutionCode &lt;chr&gt;,\n#   institutionID &lt;chr&gt;, kingdom &lt;chr&gt;, language &lt;chr&gt;, locality &lt;chr&gt;, …\n\n\nAs you can see, the returned object is a tibble and you can work with it as any other regular data frame. So, for example, to get all records from Brazil, we can simply use this:\n\nspecies_br &lt;- species %&gt;%\n  filter(country == \"Brazil\")\n\nhead(species_br, 2)\n\n# A tibble: 2 × 127\n  basisOfRecord     class       continent country countryCode county datasetName\n  &lt;chr&gt;             &lt;chr&gt;       &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;       &lt;chr&gt;  &lt;chr&gt;      \n1 PreservedSpecimen Malacostra… &lt;NA&gt;      Brazil  &lt;NA&gt;        Paran… &lt;NA&gt;       \n2 PreservedSpecimen Malacostra… &lt;NA&gt;      Brazil  &lt;NA&gt;        Mucuri &lt;NA&gt;       \n# ℹ 120 more variables: dateIdentified &lt;chr&gt;, day &lt;chr&gt;, decimalLatitude &lt;dbl&gt;,\n#   decimalLongitude &lt;dbl&gt;, establishmentMeans &lt;chr&gt;, eventDate &lt;chr&gt;,\n#   eventID &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;, geodeticDatum &lt;chr&gt;,\n#   georeferenceVerificationStatus &lt;chr&gt;, georeferencedBy &lt;chr&gt;,\n#   georeferencedDate &lt;chr&gt;, habitat &lt;chr&gt;, higherClassification &lt;chr&gt;,\n#   identifiedBy &lt;chr&gt;, identifiedByID &lt;chr&gt;, institutionCode &lt;chr&gt;,\n#   institutionID &lt;chr&gt;, kingdom &lt;chr&gt;, language &lt;chr&gt;, locality &lt;chr&gt;, …\n\n\nSaving a data frame to Parquet is also simple, and is done through the write_parquet function:\n\nwrite_parquet(species_br, \"leptuca_thayeri_br.parquet\")\n\n\n\nOpening larger-than-memory files\nWhile using Parquet files for smaller datasets is also relevant (remember: it’s several times lighter!), the real power of Parquet (and Arrow) is the ability to work with large datasets without the need to load all the data to memory. Suppose you want to get the number of records available on OBIS for each Teleostei species. This would involve loading all the OBIS database in the memory before filtering the data. If you ever tried that, it’s quite probable that your R crashed. However, with Arrow this is a straightforward task.\nFor this part of the tutorial, we will work with the full export of the OBIS database which you can download here: https://obis.org/data/access/. The file have ~15GB.\n\nobis_file &lt;- \"obis_20230726.parquet\" # The path to the file\n\nThis time, instead of using read_parquet we will use the function open_dataset. The function will not read all the file into memory, but will instead read a “schema” showing how the file is organized.\n\nobis &lt;- open_dataset(obis_file)\n\nIf you print the obis object you will see that it is not a data frame, but instead a FileSytemDataset object, showing the columns of the table with their respective data types. So how can we access the data? Arrow support dplyr verbs that enable us to work with the data without loading it. So in our case we can filter the data as usual:\n\nteleostei &lt;- obis %&gt;%\n  filter(class == \"Teleostei\") %&gt;%\n  filter(taxonRank == \"Species\") %&gt;%\n  group_by(species) %&gt;%\n  summarise(records = n()) %&gt;%\n  collect()\n\nhead(teleostei)\n\n# A tibble: 6 × 2\n  species                 records\n  &lt;chr&gt;                     &lt;int&gt;\n1 Sebastes maliger          41380\n2 Pycnochromis acares        8724\n3 Gymnothorax fimbriatus      857\n4 Monotaxis grandoculis     10961\n5 Ctenochaetus flavicauda    1297\n6 Sargocentron tiere         3687\n\n\nDepending on the filters it may take a few seconds before the data is returned. Note that after all the filters we added collect(), what indicates to Arrow that it should process our request. Several dplyr verbs are available to use with Arrow, a full list can be found here.\nWhen working with large datasets, it’s important that your filter produces an object of reasonable size (i.e., that after collect() can be loaded in memory).\nIf you need to inspect the data before filtering, its possible to load only a slice of the data with slice_head:\n\nobis %&gt;%\n  select(class, taxonRank, species) %&gt;% # Select just a few columns\n  slice_head(n = 5) %&gt;% # Select the first 5 lines\n  collect() # Process the request\n\n# A tibble: 5 × 3\n  class     taxonRank species               \n  &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;                 \n1 Teleostei Species   Sebastes maliger      \n2 Teleostei Species   Pycnochromis acares   \n3 Teleostei Species   Pycnochromis acares   \n4 Teleostei Species   Pycnochromis acares   \n5 Teleostei Species   Gymnothorax fimbriatus\n\n\n\n\nLearning more\nThis tutorial barely scratches the surface of the full potential of working with Parquet. For example, it’s possible to save Parquet datasets in a way that only certain parts of the data need to be read, what can improve even more the computation. The better place to learn more about Arrow is the package website which contain several useful articles - https://arrow.apache.org/docs/dev/r/index.html\nYou can also see this tutorial on using Parquet with GBIF data: https://data-blog.gbif.org/post/apache-arrow-and-parquet/"
  }
]